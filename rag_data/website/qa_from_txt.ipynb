{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web data from __[telekom.de](https://www.telekom.de/hilfe)__\n",
    "\n",
    "\n",
    "### Description\n",
    "This function processes `.txt` files in a specified directory to extract relevant information and write it to different output files based on their content. It categorizes the files into three categories:\n",
    "1. **Files with valid questions and answers**: Written to `web_data.txt`.\n",
    "2. **Files that could not be processed**: Written to `filtered.txt`.\n",
    "3. **Files with questions containing `?` but not ending with `?`**: Written to `inspecting.txt`.\n",
    "\n",
    "### Inputs\n",
    "- **`directory_path`**: Path to the directory containing `.txt` files.\n",
    "- **`web_data_file`**: Path to the output file for valid questions and answers.\n",
    "- **`filtered_file`**: Path to the output file for files that couldn't be processed.\n",
    "- **`inspecting_file`**: Path to the output file for questions containing `?` but not ending with `?`.\n",
    "\n",
    "### Outputs\n",
    "- **`web_data.txt`**: Contains the valid question and answer data.\n",
    "- **`filtered.txt`**: Contains filenames of files that couldn't be processed.\n",
    "- **`inspecting.txt`**: Contains questions with `?` but not ending with `?` along with their details.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "\n",
    "# Define fixed paths for the input directory and output files\n",
    "directory_path = \"/Users/taha/Desktop/scrapeV2/output_folder\"\n",
    "web_data_directory = \"web_data\"\n",
    "web_data_file = os.path.join(web_data_directory, \"web_data.txt\")\n",
    "filtered_file = os.path.join(web_data_directory, \"filtered.txt\")\n",
    "inspecting_file = os.path.join(web_data_directory, \"inspecting.txt\")\n",
    "\n",
    "def extract_and_write_data(directory_path, web_data_file, filtered_file, inspecting_file):\n",
    "    \"\"\"\n",
    "    Extracts and categorizes data from .txt files in the specified directory.\n",
    "    \n",
    "    Parameters:\n",
    "    - directory_path (str): Path to the directory containing .txt files.\n",
    "    - web_data_file (str): Path to the output file for valid questions and answers.\n",
    "    - filtered_file (str): Path to the output file for files that couldn't be processed.\n",
    "    - inspecting_file (str): Path to the output file for questions containing `?` but not ending with `?`.\n",
    "    \n",
    "    Outputs:\n",
    "    - Writes valid questions and answers to web_data_file.\n",
    "    - Writes filenames of unprocessed files to filtered_file.\n",
    "    - Writes questions with `?` but not ending with `?` to inspecting_file.\n",
    "    \"\"\"\n",
    "\n",
    "    # Regex pattern to find the section starting with \"...Telekom\" and ending with two spaces\n",
    "    pattern = r\"\\.\\.\\.Telekom.*?\\s{2}\"\n",
    "    \n",
    "    # Initialize counters and lists to keep track of files and their processing\n",
    "    total_files = 0\n",
    "    processed_files = 0\n",
    "    processed_files_data = []\n",
    "    unprocessed_files = []\n",
    "    inspecting_files = []\n",
    "\n",
    "    def process_file(filename):\n",
    "        \"\"\"\n",
    "        Processes each .txt file to extract and categorize content based on patterns.\n",
    "        \n",
    "        Parameters:\n",
    "        - filename (str): The name of the file to be processed.\n",
    "        \"\"\"\n",
    "        nonlocal processed_files\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "        try:\n",
    "            with open(file_path, \"r\", encoding=\"utf-8\") as source:\n",
    "                content = source.read()\n",
    "                match = re.search(pattern, content, re.DOTALL)\n",
    "                if match:\n",
    "                    processed_files += 1\n",
    "                    matched_text = match.group(0)\n",
    "                    start_index = match.end()\n",
    "\n",
    "                    # Clean and format the matched text\n",
    "                    cleaned_text = re.sub(r'\\.\\.\\.+', '\\n', matched_text.strip(\".\").strip())\n",
    "                    \n",
    "                    # Extract the text after the matched pattern\n",
    "                    post_pattern_text = content[start_index:]\n",
    "                    \n",
    "                    # Find paragraphs separated by multiple newlines\n",
    "                    paragraph_pattern = r'([^\\n]+(?:\\n[^\\n]+)*)(?:\\n{2,})'\n",
    "                    paragraphs = re.findall(paragraph_pattern, post_pattern_text)\n",
    "                    \n",
    "                    if len(paragraphs) >= 2:\n",
    "                        question = paragraphs[0].strip()\n",
    "                        answer = paragraphs[1].strip()\n",
    "                        \n",
    "                        if question.endswith('?'):\n",
    "                            processed_files_data.append((filename, cleaned_text, question, answer))\n",
    "                        else:\n",
    "                            if '?' in question:\n",
    "                                inspecting_files.append(f\"File: {filename}\\nNavigation:\\n{cleaned_text}\\n\\nQuestion: {question}\\n\\nAnswer: {answer}\\n\")\n",
    "                    else:\n",
    "                        unprocessed_files.append(filename)\n",
    "                else:\n",
    "                    unprocessed_files.append(filename)\n",
    "        except Exception as e:\n",
    "            unprocessed_files.append(filename)\n",
    "\n",
    "    # Check if the directory exists\n",
    "    if not os.path.exists(directory_path):\n",
    "        print(f\"Directory {directory_path} does not exist.\")\n",
    "        return\n",
    "\n",
    "    # Create web_data directory if it does not exist\n",
    "    os.makedirs(web_data_directory, exist_ok=True)\n",
    "\n",
    "    # Process each .txt file in the directory\n",
    "    for filename in sorted(os.listdir(directory_path)):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            total_files += 1\n",
    "            process_file(filename)\n",
    "\n",
    "    # Write valid question and answer data to web_data_file\n",
    "    with open(web_data_file, \"w\", encoding=\"utf-8\") as web_data_txt:\n",
    "        for filename, navigation, question, answer in sorted(processed_files_data, key=lambda x: x[0]):\n",
    "            web_data_txt.write(f\"File: {filename}\\n\")\n",
    "            web_data_txt.write(f\"Navigation:\\n{navigation}\\n\\n\")\n",
    "            web_data_txt.write(f\"Question: {question}\\n\\n\")\n",
    "            web_data_txt.write(f\"Answer: {answer}\\n\")\n",
    "            web_data_txt.write(\"\\n\" + \"=\"*40 + \"\\n\")\n",
    "\n",
    "    # Write filenames of unprocessed files to filtered_file\n",
    "    with open(filtered_file, \"w\", encoding=\"utf-8\") as filtered_txt:\n",
    "        for filename in sorted(unprocessed_files):\n",
    "            filtered_txt.write(f\"{filename}\\n\")\n",
    "\n",
    "    # Write questions with `?` but not ending with `?` to inspecting_file\n",
    "    with open(inspecting_file, \"w\", encoding=\"utf-8\") as inspecting_txt:\n",
    "        inspecting_txt.writelines(inspecting_files)\n",
    "\n",
    "    # Calculate numbers for print statements\n",
    "    num_unprocessed_files = len(unprocessed_files)\n",
    "    num_inspecting_files = len(inspecting_files)\n",
    "    num_processed_files = len(processed_files_data)\n",
    "    missing_files = total_files - (num_processed_files + num_unprocessed_files + num_inspecting_files)\n",
    "\n",
    "    # Print summary of the processing\n",
    "    print(\"Process completed.\")\n",
    "    print(f\"Total number of .txt files in the folder: {total_files}\")\n",
    "    print(f\"Number of .txt files processed and written to {web_data_file}: {num_processed_files}\")\n",
    "    print(f\"Unprocessed files have been written to {filtered_file}. Number of unprocessed files: {num_unprocessed_files}\")\n",
    "    print(f\"Files with questions containing '?' but not ending with '?' have been written to {inspecting_file}. Number of inspecting files: {num_inspecting_files}\")\n",
    "    print(f\"Number of missing or unaccounted files: {missing_files}\")\n",
    "\n",
    "# Call the function with the specified parameters\n",
    "extract_and_write_data(directory_path, web_data_file, filtered_file, inspecting_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process completed.\n",
      "Total number of .txt files in the folder: 2595\n",
      "Number of .txt files processed and written to web_data/navigation.txt: 1676\n",
      "Unprocessed files: 919\n",
      "Number of missing or unaccounted files: 0\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import logging\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(filename='processing.log', level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Define fixed paths for the input directory and output file\n",
    "directory_path = \"/Users/taha/Desktop/scrapeV2/output_folder\"\n",
    "web_data_directory = \"web_data\"\n",
    "navigation_file = os.path.join(web_data_directory, \"navigation.txt\")\n",
    "\n",
    "def format_navigation_text(text):\n",
    "    \"\"\"\n",
    "    Formats the navigation text by replacing newlines and multiple spaces with ' > '.\n",
    "    \n",
    "    Parameters:\n",
    "    - text (str): The text to be formatted.\n",
    "    \n",
    "    Returns:\n",
    "    - str: The formatted text with ' > ' as separators.\n",
    "    \"\"\"\n",
    "    # Replace newlines and multiple spaces with a single space\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    # Replace single spaces with ' > ' for navigation format\n",
    "    formatted_text = re.sub(r'\\s* \\s*', ' > ', text)\n",
    "    \n",
    "    return formatted_text\n",
    "\n",
    "def extract_navigation_data(directory_path, navigation_file):\n",
    "    \"\"\"\n",
    "    Extracts navigation data from .txt files in the specified directory and writes it to an output file.\n",
    "    \n",
    "    Parameters:\n",
    "    - directory_path (str): Path to the directory containing .txt files.\n",
    "    - navigation_file (str): Path to the output file for navigation data.\n",
    "    \n",
    "    Outputs:\n",
    "    - Writes navigation data to navigation_file.\n",
    "    \"\"\"\n",
    "\n",
    "    # Regex pattern to find the section starting with \"...Telekom\" and ending with two spaces\n",
    "    pattern = r\"\\.\\.\\.Telekom.*?\\s{2}\"\n",
    "    \n",
    "    # Initialize lists to keep track of processed and unprocessed files\n",
    "    processed_files_data = []\n",
    "    unprocessed_files = []\n",
    "\n",
    "    def process_file(filename):\n",
    "        \"\"\"\n",
    "        Processes each .txt file to extract navigation content based on patterns.\n",
    "        \n",
    "        Parameters:\n",
    "        - filename (str): The name of the file to be processed.\n",
    "        \"\"\"\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "        try:\n",
    "            with open(file_path, \"r\", encoding=\"utf-8\") as source:\n",
    "                content = source.read()\n",
    "                match = re.search(pattern, content, re.DOTALL)\n",
    "                if match:\n",
    "                    matched_text = match.group(0)\n",
    "                    start_index = match.end()\n",
    "\n",
    "                    # Clean and format the matched text\n",
    "                    cleaned_text = re.sub(r'\\.\\.\\.+', '\\n', matched_text.strip(\".\").strip())\n",
    "                    \n",
    "                    # Extract the text after the matched pattern\n",
    "                    post_pattern_text = content[start_index:]\n",
    "                    \n",
    "                    # Find paragraphs separated by multiple newlines\n",
    "                    paragraph_pattern = r'([^\\n]+(?:\\n[^\\n]+)*)(?:\\n{2,})'\n",
    "                    paragraphs = re.findall(paragraph_pattern, post_pattern_text)\n",
    "                    \n",
    "                    if len(paragraphs) >= 1:\n",
    "                        # Format navigation text\n",
    "                        navigation = format_navigation_text(cleaned_text)\n",
    "                        processed_files_data.append((filename, navigation))\n",
    "                    else:\n",
    "                        unprocessed_files.append(filename)\n",
    "                else:\n",
    "                    unprocessed_files.append(filename)\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error processing file {filename}: {e}\")\n",
    "            unprocessed_files.append(filename)\n",
    "\n",
    "    # Ensure the directory exists\n",
    "    if not os.path.exists(directory_path):\n",
    "        logging.error(f\"Directory {directory_path} does not exist.\")\n",
    "        return\n",
    "\n",
    "    # Create web_data directory if it does not exist\n",
    "    os.makedirs(web_data_directory, exist_ok=True)\n",
    "\n",
    "    # Process each .txt file in the directory\n",
    "    for filename in sorted(os.listdir(directory_path)):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            process_file(filename)\n",
    "\n",
    "    # Write navigation data to the navigation_file\n",
    "    with open(navigation_file, \"w\", encoding=\"utf-8\") as nav_file:\n",
    "        for filename, navigation in sorted(processed_files_data, key=lambda x: x[0]):\n",
    "            # Prepend \"https_\" to the filename\n",
    "            nav_file.write(f\"https_{filename}\\n\")\n",
    "            nav_file.write(f\"{navigation}\\n\")\n",
    "            nav_file.write(\"\\n\" + \"=\"*40 + \"\\n\")\n",
    "\n",
    "    # Print summary of the processing\n",
    "    total_files = len(processed_files_data) + len(unprocessed_files)\n",
    "    num_processed_files = len(processed_files_data)\n",
    "    num_unprocessed_files = len(unprocessed_files)\n",
    "    missing_files = total_files - (num_processed_files + num_unprocessed_files)\n",
    "\n",
    "    print(\"Process completed.\")\n",
    "    print(f\"Total number of .txt files in the folder: {total_files}\")\n",
    "    print(f\"Number of .txt files processed and written to {navigation_file}: {num_processed_files}\")\n",
    "    print(f\"Unprocessed files: {num_unprocessed_files}\")\n",
    "    print(f\"Number of missing or unaccounted files: {missing_files}\")\n",
    "\n",
    "    # Log the results\n",
    "    logging.info(f\"Total files: {total_files}\")\n",
    "    logging.info(f\"Processed files: {num_processed_files}\")\n",
    "    logging.info(f\"Unprocessed files: {num_unprocessed_files}\")\n",
    "    logging.info(f\"Missing files: {missing_files}\")\n",
    "\n",
    "# Call the function with the specified parameters\n",
    "extract_navigation_data(directory_path, navigation_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
