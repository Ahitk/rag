{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Naive RAG - Semantic Search - Character Splitting - Recursive Character Text Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taha/Desktop/rag/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package punkt to /Users/taha/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /Users/taha/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created output file at: test_data_naive/_evaluation_naive_semantic.csv\n",
      "Processing question 1/10: What steps should be taken to remove the Telekom Login from the Puls-Tablet?\n",
      "==========   CHUNKS CREATED  ==========\n",
      "==========   VECTORSTORE CREATED  ==========\n",
      "==========   ANSWER GENERATED  ==========\n",
      "==========   EVALUATION  ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 4/4 [00:07<00:00,  1.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for question 'What steps should be taken to remove the Telekom Login from the Puls-Tablet?': {'answer_relevancy': 0.9699543996291394, 'context_precision': 0.0, 'context_recall': 0.0, 'faithfulness': 0.2, 'bleu_score': 0.0025963742211370646, 'rouge_score': 0.02298850574712644}\n",
      "Evaluation metrics saved for question 'What steps should be taken to remove the Telekom Login from the Puls-Tablet?'.\n",
      "==========   PROCESS ENDED  ==========\n",
      "\n",
      "Processing question 2/10: Wie können Sie Ihre Bestellung stornieren?\n",
      "==========   CHUNKS CREATED  ==========\n",
      "==========   VECTORSTORE CREATED  ==========\n",
      "==========   ANSWER GENERATED  ==========\n",
      "==========   EVALUATION  ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 4/4 [00:08<00:00,  2.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for question 'Wie können Sie Ihre Bestellung stornieren?': {'answer_relevancy': 0.8205745212554838, 'context_precision': 0.99999999995, 'context_recall': 1.0, 'faithfulness': 0.8, 'bleu_score': 0.02963113348896942, 'rouge_score': 0.1917808219178082}\n",
      "Evaluation metrics saved for question 'Wie können Sie Ihre Bestellung stornieren?'.\n",
      "==========   PROCESS ENDED  ==========\n",
      "\n",
      "Processing question 3/10: What is the requirement for devices to support UHD media in relation to HDCP 2.2?\n",
      "==========   CHUNKS CREATED  ==========\n",
      "==========   VECTORSTORE CREATED  ==========\n",
      "==========   ANSWER GENERATED  ==========\n",
      "==========   EVALUATION  ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 4/4 [00:06<00:00,  1.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for question 'What is the requirement for devices to support UHD media in relation to HDCP 2.2?': {'answer_relevancy': 0.8769927536875995, 'context_precision': 0.0, 'context_recall': 0.0, 'faithfulness': 0.0, 'bleu_score': 0.007517522301994743, 'rouge_score': 0.12389380530973451}\n",
      "Evaluation metrics saved for question 'What is the requirement for devices to support UHD media in relation to HDCP 2.2?'.\n",
      "==========   PROCESS ENDED  ==========\n",
      "\n",
      "Processing question 4/10: What ist die Lösung für das Einstellen von Untertiteln auf Magenta TV?\n",
      "==========   CHUNKS CREATED  ==========\n",
      "==========   VECTORSTORE CREATED  ==========\n",
      "==========   ANSWER GENERATED  ==========\n",
      "==========   EVALUATION  ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 4/4 [00:08<00:00,  2.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for question 'What ist die Lösung für das Einstellen von Untertiteln auf Magenta TV?': {'answer_relevancy': 0.96285001139216, 'context_precision': 0.999999999975, 'context_recall': 1.0, 'faithfulness': 1.0, 'bleu_score': 0.04084684128649013, 'rouge_score': 0.3913043478260869}\n",
      "Evaluation metrics saved for question 'What ist die Lösung für das Einstellen von Untertiteln auf Magenta TV?'.\n",
      "==========   PROCESS ENDED  ==========\n",
      "\n",
      "Processing question 5/10: What muss ich tun, wenn die Registrierung der Rufnummer nicht funktioniert?\n",
      "==========   CHUNKS CREATED  ==========\n",
      "==========   VECTORSTORE CREATED  ==========\n",
      "==========   ANSWER GENERATED  ==========\n",
      "==========   EVALUATION  ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 4/4 [00:11<00:00,  2.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for question 'What muss ich tun, wenn die Registrierung der Rufnummer nicht funktioniert?': {'answer_relevancy': 0.9149670707169014, 'context_precision': 0.249999999975, 'context_recall': 1.0, 'faithfulness': 0.7142857142857143, 'bleu_score': 0.0024005140614996685, 'rouge_score': 0.06451612903225806}\n",
      "Evaluation metrics saved for question 'What muss ich tun, wenn die Registrierung der Rufnummer nicht funktioniert?'.\n",
      "==========   PROCESS ENDED  ==========\n",
      "\n",
      "Processing question 6/10: Wie aktiviere ich das Telekom Sicherheitspaket?\n",
      "==========   CHUNKS CREATED  ==========\n",
      "==========   VECTORSTORE CREATED  ==========\n",
      "==========   ANSWER GENERATED  ==========\n",
      "==========   EVALUATION  ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 4/4 [00:06<00:00,  1.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for question 'Wie aktiviere ich das Telekom Sicherheitspaket?': {'answer_relevancy': 0.9701252009419767, 'context_precision': 0.999999999975, 'context_recall': 1.0, 'faithfulness': 0.3333333333333333, 'bleu_score': 0.09668836899664966, 'rouge_score': 0.2972972972972973}\n",
      "Evaluation metrics saved for question 'Wie aktiviere ich das Telekom Sicherheitspaket?'.\n",
      "==========   PROCESS ENDED  ==========\n",
      "\n",
      "Processing question 7/10: Who to contact for order cancellation within the Widerrufsfrist?\n",
      "==========   CHUNKS CREATED  ==========\n",
      "==========   VECTORSTORE CREATED  ==========\n",
      "==========   ANSWER GENERATED  ==========\n",
      "==========   EVALUATION  ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 4/4 [00:05<00:00,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for question 'Who to contact for order cancellation within the Widerrufsfrist?': {'answer_relevancy': 0.912176632632328, 'context_precision': 0.999999999975, 'context_recall': 1.0, 'faithfulness': 1.0, 'bleu_score': 0.2764393753270045, 'rouge_score': 0.43478260869565216}\n",
      "Evaluation metrics saved for question 'Who to contact for order cancellation within the Widerrufsfrist?'.\n",
      "==========   PROCESS ENDED  ==========\n",
      "\n",
      "Processing question 8/10: How to fix the thermostat display in the MagentaZuhause App if it's upside down?\n",
      "==========   CHUNKS CREATED  ==========\n",
      "==========   VECTORSTORE CREATED  ==========\n",
      "==========   ANSWER GENERATED  ==========\n",
      "==========   EVALUATION  ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 4/4 [00:07<00:00,  1.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for question 'How to fix the thermostat display in the MagentaZuhause App if it's upside down?': {'answer_relevancy': 0.9743488514503057, 'context_precision': 0.999999999975, 'context_recall': 1.0, 'faithfulness': 1.0, 'bleu_score': 0.007156562786973337, 'rouge_score': 0.12612612612612611}\n",
      "Evaluation metrics saved for question 'How to fix the thermostat display in the MagentaZuhause App if it's upside down?'.\n",
      "==========   PROCESS ENDED  ==========\n",
      "\n",
      "Processing question 9/10: How to adjust subtitle quality on Magenta TV?\n",
      "==========   CHUNKS CREATED  ==========\n",
      "==========   VECTORSTORE CREATED  ==========\n",
      "==========   ANSWER GENERATED  ==========\n",
      "==========   EVALUATION  ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 4/4 [00:07<00:00,  1.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for question 'How to adjust subtitle quality on Magenta TV?': {'answer_relevancy': 0.0, 'context_precision': 0.999999999975, 'context_recall': 1.0, 'faithfulness': 1.0, 'bleu_score': 0.012362883593468847, 'rouge_score': 0.25000000000000006}\n",
      "Evaluation metrics saved for question 'How to adjust subtitle quality on Magenta TV?'.\n",
      "==========   PROCESS ENDED  ==========\n",
      "\n",
      "Processing question 10/10: What's the first step for the Telekom security check after Google or Apple login in the GÖNN app?\n",
      "==========   CHUNKS CREATED  ==========\n",
      "==========   VECTORSTORE CREATED  ==========\n",
      "==========   ANSWER GENERATED  ==========\n",
      "==========   EVALUATION  ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 4/4 [00:06<00:00,  1.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for question 'What's the first step for the Telekom security check after Google or Apple login in the GÖNN app?': {'answer_relevancy': 0.9953298780856693, 'context_precision': 0.999999999975, 'context_recall': 1.0, 'faithfulness': 1.0, 'bleu_score': 0.36889932716584156, 'rouge_score': 0.6355140186915887}\n",
      "Evaluation metrics saved for question 'What's the first step for the Telekom security check after Google or Apple login in the GÖNN app?'.\n",
      "==========   PROCESS ENDED  ==========\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import glob\n",
    "from langchain_community.document_loaders import DirectoryLoader, TextLoader\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.callbacks import get_openai_callback\n",
    "from langchain_text_splitters import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_chroma import Chroma\n",
    "import prompts as prompts\n",
    "import initials as initials\n",
    "import evaluation\n",
    "import chromadb\n",
    "\n",
    "\n",
    "test_directory = '/Users/taha/Desktop/rag/test_data_naive'\n",
    "# Define input CSV path\n",
    "input_csv_path = '/Users/taha/Desktop/rag/test_data_naive/_testset_semantic.csv'  # Input CSV file path\n",
    "\n",
    "# Define output CSV path including the filename\n",
    "output_csv_path = 'test_data_naive/_evaluation_naive_semantic.csv'  # Output file will be created here\n",
    "\n",
    "# Function to create the output CSV file at the beginning\n",
    "def initialize_output_csv(output_path):\n",
    "    # Directly create the file with the correct header\n",
    "    with open(output_path, 'w') as file:\n",
    "        header = (\n",
    "            \"Question,Response,Contexts,Ground Truth,\"\n",
    "            \"Token Count,Total Cost (USD),Completion Tokens,Number of Retrieved documents,\"\n",
    "            \"Response time,answer_relevancy,context_precision,\"\n",
    "            \"context_recall,faithfulness,BleuScore,RougeScore\\n\"\n",
    "        )\n",
    "        file.write(header)\n",
    "    print(f\"Created output file at: {output_path}\")\n",
    "\n",
    "# Function to get response with error handling\n",
    "def get_response(user_input):\n",
    "    try:\n",
    "        # Dosyaları listele\n",
    "        all_txt_files = glob.glob(os.path.join(test_directory, \"*.txt\"))\n",
    "    \n",
    "        # Seçilen dosyaların içeriklerini oku ve birleştir\n",
    "        all_texts = []\n",
    "        for file_path in all_txt_files:\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                all_texts.append(f.read())\n",
    "\n",
    "        # CharacterTextSplitter without separator\n",
    "        text_splitter = CharacterTextSplitter(\n",
    "            separator='',\n",
    "            chunk_size=500,\n",
    "            chunk_overlap=100,\n",
    "        )\n",
    "\n",
    "        # CharacterTextSplitter with separator\n",
    "        text_splitter_separator = CharacterTextSplitter(\n",
    "            separator=\"\\n\\n\",\n",
    "            chunk_size=500,\n",
    "            chunk_overlap=100,\n",
    "        )\n",
    "\n",
    "        #RecursiveCharacterTextSplitter\n",
    "        text_splitter_recursive = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
    "\n",
    "        # Semantic Splitting\n",
    "        text_splitter_semantic = SemanticChunker(initials.embedding)\n",
    "        \n",
    "        chunks = text_splitter_recursive.create_documents(all_texts)\n",
    "        print(\"==========   CHUNKS CREATED  ==========\")\n",
    "\n",
    "        # Embedding işlemi\n",
    "        vectorstore = Chroma.from_documents(documents=chunks, embedding=initials.embedding)\n",
    "        print(\"==========   VECTORSTORE CREATED  ==========\")\n",
    "        retriever = vectorstore.as_retriever()\n",
    "        retrieved_docs = retriever.invoke(user_input)\n",
    "\n",
    "        # Prompt oluşturma\n",
    "        rag_chain = (prompts.prompt_telekom | initials.model | StrOutputParser())\n",
    "\n",
    "        # OpenAI callback ile maliyet ve token takibi\n",
    "        with get_openai_callback() as cb:\n",
    "            response = rag_chain.invoke({\n",
    "                \"context\": retrieved_docs, \n",
    "                \"question\": user_input,\n",
    "                \"chat_history\": []\n",
    "            }) if retrieved_docs else \"No relevant documents found.\"\n",
    "\n",
    "        total_tokens = cb.total_tokens\n",
    "        total_cost = cb.total_cost\n",
    "        completion_tokens = cb.completion_tokens\n",
    "\n",
    "        return response, retrieved_docs, total_cost, total_tokens, completion_tokens\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(\"Documents could not be loaded. Please check the data directory path.\")\n",
    "        return None, None, None, None, None\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "        return None, None, None, None, None\n",
    "\n",
    "\n",
    "# Function to save evaluation data to CSV\n",
    "def save_evaluation_to_csv(evaluation_data, filename):\n",
    "    df = pd.DataFrame([evaluation_data])\n",
    "    df.to_csv(filename, mode='a', index=False, header=False)\n",
    "\n",
    "# Main execution\n",
    "def run_evaluations_from_csv(input_csv, output_csv):\n",
    "    # Directly create the output CSV file with headers at the beginning\n",
    "    initialize_output_csv(output_csv)\n",
    "\n",
    "    # Load questions from the CSV file\n",
    "    questions_df = pd.read_csv(input_csv)\n",
    "    \n",
    "    for index, row in questions_df.iterrows():\n",
    "        user_query = row['question']\n",
    "        start_time = time.time()  # Start timing\n",
    "        print(f\"Processing question {index + 1}/{len(questions_df)}: {user_query}\")\n",
    "\n",
    "        try:\n",
    "            # Get the response, generated queries, and retrieved documents\n",
    "            response, context, total_cost, total_tokens, completion_tokens = get_response(user_query)\n",
    "            print(\"==========   ANSWER GENERATED  ==========\")\n",
    "\n",
    "            # Initialize metrics_results\n",
    "            metrics_results = None\n",
    "\n",
    "            print(\"==========   EVALUATION  ==========\")\n",
    "            # Evaluate metrics and retrieve dataset\n",
    "            metrics_results, dataset = evaluation.evaluate_result(user_query, response, context, input_csv)\n",
    "            print(f\"Metrics for question '{user_query}': {metrics_results}\")\n",
    "\n",
    "            if response:\n",
    "                # Calculate response time\n",
    "                response_time = time.time() - start_time\n",
    "                # Clear the system cache after processing the response\n",
    "                chromadb.api.client.SharedSystemClient.clear_system_cache()\n",
    "\n",
    "                # Prepare data for CSV\n",
    "                if metrics_results is not None:\n",
    "                    # Extract contexts and ground_truth from the dataset\n",
    "                    contexts = dataset[\"contexts\"][0]  # Access first row's 'contexts'\n",
    "                    ground_truth = dataset[\"ground_truth\"][0]  # Access first row's 'ground_truth'\n",
    "                    \n",
    "                    evaluation_data = {\n",
    "                        'Question': user_query,\n",
    "                        'Response': response,\n",
    "                        'Contexts': contexts,\n",
    "                        'Ground Truth': ground_truth,\n",
    "                        'Token Count': total_tokens,\n",
    "                        'Total Cost (USD)': total_cost,\n",
    "                        'Completion Tokens': completion_tokens,\n",
    "                        'Number of Retrieved documents': len(context),\n",
    "                        'Response time': response_time,\n",
    "                        'answer_relevancy': metrics_results.get('answer_relevancy'),\n",
    "                        'context_precision': metrics_results.get('context_precision'),\n",
    "                        'context_recall': metrics_results.get('context_recall'),\n",
    "                        'faithfulness': metrics_results.get('faithfulness'),\n",
    "                        'BleuScore': metrics_results.get('bleu_score'),\n",
    "                        'RougeScore': metrics_results.get('rouge_score'),\n",
    "\n",
    "                    }\n",
    "\n",
    "                    # Save the evaluation data to CSV\n",
    "                    save_evaluation_to_csv(evaluation_data, output_csv)\n",
    "                    print(f\"Evaluation metrics saved for question '{user_query}'.\")\n",
    "\n",
    "            print(\"==========   PROCESS ENDED  ==========\\n\")\n",
    "\n",
    "        except ValueError as ve:\n",
    "            print(f\"ValueError for question {index + 1}: {ve}\")\n",
    "            print(\"Skipping to the next question...\\n\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Unexpected error for question {index + 1}: {e}\")\n",
    "            print(\"Skipping to the next question...\\n\")\n",
    "\n",
    "\n",
    "# Run evaluations\n",
    "run_evaluations_from_csv(input_csv_path, output_csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Formatted averages saved to /Users/taha/Desktop/rag/test_data_naive/_results__evaluation_naive_semantic.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "file_path = '/Users/taha/Desktop/rag/test_data_naive/_evaluation_naive_semantic.csv'  # Replace with the path to your CSV file\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# List of numeric columns to calculate averages\n",
    "numeric_columns = [\n",
    "    'Token Count', 'Total Cost (USD)', 'Completion Tokens',\n",
    "    'Number of Retrieved documents', 'Response time',\n",
    "    'answer_relevancy', 'context_precision', 'context_recall',\n",
    "    'faithfulness', 'BleuScore', 'RougeScore'\n",
    "]\n",
    "\n",
    "# Calculate the mean for each numeric column\n",
    "averages = df[numeric_columns].mean()\n",
    "\n",
    "# Formatting the averages according to your requirements\n",
    "formatted_averages = {\n",
    "    'Token Count': f\"{averages['Token Count']:.0f}\",  # No decimal places\n",
    "    'Total Cost (USD)': f\"{averages['Total Cost (USD)']:.5f}\",  # Keep as is\n",
    "    'Completion Tokens': f\"{averages['Completion Tokens']:.0f}\",  # No decimal places\n",
    "    'Number of Retrieved documents': f\"{averages['Number of Retrieved documents']}\",  # Keep as is\n",
    "    'Response time': f\"{averages['Response time']:.1f}\",  # One decimal place\n",
    "    'answer_relevancy': f\"{averages['answer_relevancy']:.4f}\",  # Four decimal places\n",
    "    'context_precision': f\"{averages['context_precision']:.4f}\",  # Four decimal places\n",
    "    'context_recall': f\"{averages['context_recall']:.4f}\",  # Four decimal places\n",
    "    'faithfulness': f\"{averages['faithfulness']:.4f}\",  # Four decimal places\n",
    "    'BleuScore': f\"{averages['BleuScore']:.4f}\",  # Four decimal places\n",
    "    'RougeScore': f\"{averages['RougeScore']:.4f}\"  # Four decimal places\n",
    "}\n",
    "\n",
    "# Convert formatted averages to a DataFrame for saving\n",
    "formatted_averages_df = pd.DataFrame([formatted_averages])\n",
    "\n",
    "# Define the output file path by adding \"results_\" prefix\n",
    "output_file_path = os.path.join(\n",
    "    os.path.dirname(file_path), \n",
    "    f\"_results_{os.path.basename(file_path)}\"\n",
    ")\n",
    "\n",
    "# Save the formatted averages to CSV\n",
    "formatted_averages_df.to_csv(output_file_path, index=False)\n",
    "print(f\"[INFO] Formatted averages saved to {output_file_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
