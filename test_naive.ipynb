{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation - Naive RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Naive RAG - Semantic Search - Character Splitting - Recursive Character Text Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created output file at: test_data_naive/_evaluation_naive_semantic_gradient.csv\n",
      "Processing question 1/10: Was sind die Vorteile der Nutzung der MeinMagenta App für GÖNN Kunden?\n",
      "==========   CHUNKS CREATED  ==========\n",
      "==========   VECTORSTORE CREATED  ==========\n",
      "==========   ANSWER GENERATED  ==========\n",
      "==========   EVALUATION  ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 4/4 [00:23<00:00,  5.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for question 'Was sind die Vorteile der Nutzung der MeinMagenta App für GÖNN Kunden?': {'answer_relevancy': 0.9553970603390374, 'context_precision': 0.999999999975, 'context_recall': 1.0, 'faithfulness': 0.7333333333333333, 'bleu_score': 0.03364007721566668, 'rouge_score': 0.2634146341463415}\n",
      "Evaluation metrics saved for question 'Was sind die Vorteile der Nutzung der MeinMagenta App für GÖNN Kunden?'.\n",
      "==========   PROCESS ENDED  ==========\n",
      "\n",
      "Processing question 2/10: Wie kann ich einen AV-Receiver mit meinem TV-Receiver und Fernseher verbinden?\n",
      "==========   CHUNKS CREATED  ==========\n",
      "==========   VECTORSTORE CREATED  ==========\n",
      "==========   ANSWER GENERATED  ==========\n",
      "==========   EVALUATION  ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 4/4 [00:12<00:00,  3.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for question 'Wie kann ich einen AV-Receiver mit meinem TV-Receiver und Fernseher verbinden?': {'answer_relevancy': 0.9817467081303711, 'context_precision': 0.0, 'context_recall': 1.0, 'faithfulness': 0.5714285714285714, 'bleu_score': 0.002939806889647791, 'rouge_score': 0.045454545454545456}\n",
      "Evaluation metrics saved for question 'Wie kann ich einen AV-Receiver mit meinem TV-Receiver und Fernseher verbinden?'.\n",
      "==========   PROCESS ENDED  ==========\n",
      "\n",
      "Processing question 3/10: Welche Funktionen bietet das Kundencenter für die Verwaltung von TV-Paketen?\n",
      "==========   CHUNKS CREATED  ==========\n",
      "==========   VECTORSTORE CREATED  ==========\n",
      "==========   ANSWER GENERATED  ==========\n",
      "==========   EVALUATION  ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 4/4 [00:07<00:00,  1.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for question 'Welche Funktionen bietet das Kundencenter für die Verwaltung von TV-Paketen?': {'answer_relevancy': 0.982257999685125, 'context_precision': 0.999999999975, 'context_recall': 1.0, 'faithfulness': 0.8, 'bleu_score': 0.005488673667067168, 'rouge_score': 0.12}\n",
      "Evaluation metrics saved for question 'Welche Funktionen bietet das Kundencenter für die Verwaltung von TV-Paketen?'.\n",
      "==========   PROCESS ENDED  ==========\n",
      "\n",
      "Processing question 4/10: What can you do in the MeinMagenta App by clicking on 'Moments'?\n",
      "==========   CHUNKS CREATED  ==========\n",
      "==========   VECTORSTORE CREATED  ==========\n",
      "==========   ANSWER GENERATED  ==========\n",
      "==========   EVALUATION  ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 4/4 [00:05<00:00,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for question 'What can you do in the MeinMagenta App by clicking on 'Moments'?': {'answer_relevancy': 0.8852915843309234, 'context_precision': 0.999999999975, 'context_recall': 1.0, 'faithfulness': 0.6666666666666666, 'bleu_score': 0.34850182406276775, 'rouge_score': 0.5833333333333334}\n",
      "Evaluation metrics saved for question 'What can you do in the MeinMagenta App by clicking on 'Moments'?'.\n",
      "==========   PROCESS ENDED  ==========\n",
      "\n",
      "Processing question 5/10: What services can you access through the Telekom Kundencenter?\n",
      "==========   CHUNKS CREATED  ==========\n",
      "==========   VECTORSTORE CREATED  ==========\n",
      "==========   ANSWER GENERATED  ==========\n",
      "==========   EVALUATION  ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 4/4 [00:09<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for question 'What services can you access through the Telekom Kundencenter?': {'answer_relevancy': 0.9816277796586625, 'context_precision': 0.0, 'context_recall': 1.0, 'faithfulness': 0.14285714285714285, 'bleu_score': 0.0039094870602888725, 'rouge_score': 0.030769230769230767}\n",
      "Evaluation metrics saved for question 'What services can you access through the Telekom Kundencenter?'.\n",
      "==========   PROCESS ENDED  ==========\n",
      "\n",
      "Processing question 6/10: Was beeinflusst die Wahl Ihres DSL-/VDSL-Tarifs bzgl. Internetgeschwindigkeit?\n",
      "==========   CHUNKS CREATED  ==========\n",
      "==========   VECTORSTORE CREATED  ==========\n",
      "==========   ANSWER GENERATED  ==========\n",
      "==========   EVALUATION  ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 4/4 [00:10<00:00,  2.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for question 'Was beeinflusst die Wahl Ihres DSL-/VDSL-Tarifs bzgl. Internetgeschwindigkeit?': {'answer_relevancy': 0.9873434713442647, 'context_precision': 0.999999999975, 'context_recall': 1.0, 'faithfulness': 0.6666666666666666, 'bleu_score': 0.08070632004040003, 'rouge_score': 0.38383838383838387}\n",
      "Evaluation metrics saved for question 'Was beeinflusst die Wahl Ihres DSL-/VDSL-Tarifs bzgl. Internetgeschwindigkeit?'.\n",
      "==========   PROCESS ENDED  ==========\n",
      "\n",
      "Processing question 7/10: What does the Verifizierungs-Link ask Android users for app install?\n",
      "==========   CHUNKS CREATED  ==========\n",
      "==========   VECTORSTORE CREATED  ==========\n",
      "==========   ANSWER GENERATED  ==========\n",
      "==========   EVALUATION  ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 4/4 [00:07<00:00,  1.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for question 'What does the Verifizierungs-Link ask Android users for app install?': {'answer_relevancy': 0.0, 'context_precision': 0.0, 'context_recall': 0.0, 'faithfulness': 0.0, 'bleu_score': 0, 'rouge_score': 0.0}\n",
      "Evaluation metrics saved for question 'What does the Verifizierungs-Link ask Android users for app install?'.\n",
      "==========   PROCESS ENDED  ==========\n",
      "\n",
      "Processing question 8/10: Wie wird WLAN Call in Dtl. abgerechnet und welches Symbol zeigt die Nutzung?\n",
      "==========   CHUNKS CREATED  ==========\n",
      "==========   VECTORSTORE CREATED  ==========\n",
      "==========   ANSWER GENERATED  ==========\n",
      "==========   EVALUATION  ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 4/4 [00:11<00:00,  2.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for question 'Wie wird WLAN Call in Dtl. abgerechnet und welches Symbol zeigt die Nutzung?': {'answer_relevancy': 0.9383452616899589, 'context_precision': 0.999999999975, 'context_recall': 0.5, 'faithfulness': 0.16666666666666666, 'bleu_score': 0.05712161481567817, 'rouge_score': 0.2777777777777778}\n",
      "Evaluation metrics saved for question 'Wie wird WLAN Call in Dtl. abgerechnet und welches Symbol zeigt die Nutzung?'.\n",
      "==========   PROCESS ENDED  ==========\n",
      "\n",
      "Processing question 9/10: How important is a unique password for Disney Plus registration?\n",
      "==========   CHUNKS CREATED  ==========\n",
      "==========   VECTORSTORE CREATED  ==========\n",
      "==========   ANSWER GENERATED  ==========\n",
      "==========   EVALUATION  ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 4/4 [00:07<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for question 'How important is a unique password for Disney Plus registration?': {'answer_relevancy': 0.9657617080555628, 'context_precision': 0.0, 'context_recall': 0.0, 'faithfulness': 0.0, 'bleu_score': 0, 'rouge_score': 0.0}\n",
      "Evaluation metrics saved for question 'How important is a unique password for Disney Plus registration?'.\n",
      "==========   PROCESS ENDED  ==========\n",
      "\n",
      "Processing question 10/10: Welche Einschränkungen gibt's bei Speedport-Kaskaden?\n",
      "==========   CHUNKS CREATED  ==========\n",
      "==========   VECTORSTORE CREATED  ==========\n",
      "==========   ANSWER GENERATED  ==========\n",
      "==========   EVALUATION  ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 4/4 [00:11<00:00,  2.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for question 'Welche Einschränkungen gibt's bei Speedport-Kaskaden?': {'answer_relevancy': 0.9626551041933255, 'context_precision': 0.6388888888675925, 'context_recall': 1.0, 'faithfulness': 0.0, 'bleu_score': 0.0038690034505641548, 'rouge_score': 0.09259259259259259}\n",
      "Evaluation metrics saved for question 'Welche Einschränkungen gibt's bei Speedport-Kaskaden?'.\n",
      "==========   PROCESS ENDED  ==========\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import glob\n",
    "from langchain_community.document_loaders import DirectoryLoader, TextLoader\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.callbacks import get_openai_callback\n",
    "from langchain_text_splitters import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_chroma import Chroma\n",
    "import prompts as prompts\n",
    "import initials as initials\n",
    "import evaluation\n",
    "import chromadb\n",
    "\n",
    "\n",
    "test_directory = '/Users/taha/Desktop/rag/test_data_naive'\n",
    "# Define input CSV path\n",
    "input_csv_path = '/Users/taha/Desktop/rag/test_data_naive/_testset_semantic_gradient.csv'  # Input CSV file path\n",
    "\n",
    "# Define output CSV path including the filename\n",
    "output_csv_path = 'test_data_naive/_evaluation_naive_semantic_gradient.csv'  # Output file will be created here\n",
    "\n",
    "# Function to create the output CSV file at the beginning\n",
    "def initialize_output_csv(output_path):\n",
    "    # Directly create the file with the correct header\n",
    "    with open(output_path, 'w') as file:\n",
    "        header = (\n",
    "            \"Question,Response,Contexts,Ground Truth,\"\n",
    "            \"Token Count,Total Cost (USD),Completion Tokens,Number of Retrieved documents,\"\n",
    "            \"Response time,answer_relevancy,context_precision,\"\n",
    "            \"context_recall,faithfulness,BleuScore,RougeScore\\n\"\n",
    "        )\n",
    "        file.write(header)\n",
    "    print(f\"Created output file at: {output_path}\")\n",
    "\n",
    "# Function to get response with error handling\n",
    "def get_response(user_input):\n",
    "    try:\n",
    "        # Dosyaları listele\n",
    "        all_txt_files = glob.glob(os.path.join(test_directory, \"*.txt\"))\n",
    "    \n",
    "        # Seçilen dosyaların içeriklerini oku ve birleştir\n",
    "        all_texts = []\n",
    "        for file_path in all_txt_files:\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                all_texts.append(f.read())\n",
    "\n",
    "        # CharacterTextSplitter without separator\n",
    "        text_splitter = CharacterTextSplitter(\n",
    "            separator='',\n",
    "            chunk_size=250,\n",
    "            chunk_overlap=25,\n",
    "        )\n",
    "\n",
    "        # CharacterTextSplitter with separator\n",
    "        text_splitter_separator = CharacterTextSplitter(\n",
    "            separator=\"\\n\\n\",\n",
    "            chunk_size=1000,\n",
    "            chunk_overlap=100,\n",
    "        )\n",
    "\n",
    "        #RecursiveCharacterTextSplitter\n",
    "        text_splitter_recursive = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
    "\n",
    "        # Semantic Splitting\n",
    "        text_splitter_semantic = SemanticChunker(embeddings=initials.embedding, breakpoint_threshold_type=\"gradient\")\n",
    "        \n",
    "        chunks = text_splitter_semantic.create_documents(all_texts)\n",
    "        print(\"==========   CHUNKS CREATED  ==========\")\n",
    "\n",
    "        # Embedding işlemi\n",
    "        vectorstore = Chroma.from_documents(documents=chunks, embedding=initials.embedding)\n",
    "        print(\"==========   VECTORSTORE CREATED  ==========\")\n",
    "        retriever = vectorstore.as_retriever()\n",
    "        retrieved_docs = retriever.invoke(user_input)\n",
    "\n",
    "        # Prompt oluşturma\n",
    "        rag_chain = (prompts.prompt_telekom | initials.model | StrOutputParser())\n",
    "\n",
    "        # OpenAI callback ile maliyet ve token takibi\n",
    "        with get_openai_callback() as cb:\n",
    "            response = rag_chain.invoke({\n",
    "                \"context\": retrieved_docs, \n",
    "                \"question\": user_input,\n",
    "                \"chat_history\": []\n",
    "            }) if retrieved_docs else \"No relevant documents found.\"\n",
    "\n",
    "        total_tokens = cb.total_tokens\n",
    "        total_cost = cb.total_cost\n",
    "        completion_tokens = cb.completion_tokens\n",
    "\n",
    "        return response, retrieved_docs, total_cost, total_tokens, completion_tokens\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(\"Documents could not be loaded. Please check the data directory path.\")\n",
    "        return None, None, None, None, None\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "        return None, None, None, None, None\n",
    "\n",
    "\n",
    "# Function to save evaluation data to CSV\n",
    "def save_evaluation_to_csv(evaluation_data, filename):\n",
    "    df = pd.DataFrame([evaluation_data])\n",
    "    df.to_csv(filename, mode='a', index=False, header=False)\n",
    "\n",
    "# Main execution\n",
    "def run_evaluations_from_csv(input_csv, output_csv):\n",
    "    # Directly create the output CSV file with headers at the beginning\n",
    "    initialize_output_csv(output_csv)\n",
    "\n",
    "    # Load questions from the CSV file\n",
    "    questions_df = pd.read_csv(input_csv)\n",
    "    \n",
    "    for index, row in questions_df.iterrows():\n",
    "        user_query = row['question']\n",
    "        start_time = time.time()  # Start timing\n",
    "        print(f\"Processing question {index + 1}/{len(questions_df)}: {user_query}\")\n",
    "\n",
    "        try:\n",
    "            # Get the response, generated queries, and retrieved documents\n",
    "            response, context, total_cost, total_tokens, completion_tokens = get_response(user_query)\n",
    "            print(\"==========   ANSWER GENERATED  ==========\")\n",
    "\n",
    "            # Initialize metrics_results\n",
    "            metrics_results = None\n",
    "\n",
    "            print(\"==========   EVALUATION  ==========\")\n",
    "            # Evaluate metrics and retrieve dataset\n",
    "            metrics_results, dataset = evaluation.evaluate_result(user_query, response, context, input_csv)\n",
    "            print(f\"Metrics for question '{user_query}': {metrics_results}\")\n",
    "\n",
    "            if response:\n",
    "                # Calculate response time\n",
    "                response_time = time.time() - start_time\n",
    "                # Clear the system cache after processing the response\n",
    "                chromadb.api.client.SharedSystemClient.clear_system_cache()\n",
    "\n",
    "                # Prepare data for CSV\n",
    "                if metrics_results is not None:\n",
    "                    # Extract contexts and ground_truth from the dataset\n",
    "                    contexts = dataset[\"contexts\"][0]  # Access first row's 'contexts'\n",
    "                    ground_truth = dataset[\"ground_truth\"][0]  # Access first row's 'ground_truth'\n",
    "                    \n",
    "                    evaluation_data = {\n",
    "                        'Question': user_query,\n",
    "                        'Response': response,\n",
    "                        'Contexts': contexts,\n",
    "                        'Ground Truth': ground_truth,\n",
    "                        'Token Count': total_tokens,\n",
    "                        'Total Cost (USD)': total_cost,\n",
    "                        'Completion Tokens': completion_tokens,\n",
    "                        'Number of Retrieved documents': len(context),\n",
    "                        'Response time': response_time,\n",
    "                        'answer_relevancy': metrics_results.get('answer_relevancy'),\n",
    "                        'context_precision': metrics_results.get('context_precision'),\n",
    "                        'context_recall': metrics_results.get('context_recall'),\n",
    "                        'faithfulness': metrics_results.get('faithfulness'),\n",
    "                        'BleuScore': metrics_results.get('bleu_score'),\n",
    "                        'RougeScore': metrics_results.get('rouge_score'),\n",
    "\n",
    "                    }\n",
    "\n",
    "                    # Save the evaluation data to CSV\n",
    "                    save_evaluation_to_csv(evaluation_data, output_csv)\n",
    "                    print(f\"Evaluation metrics saved for question '{user_query}'.\")\n",
    "\n",
    "            print(\"==========   PROCESS ENDED  ==========\\n\")\n",
    "\n",
    "        except ValueError as ve:\n",
    "            print(f\"ValueError for question {index + 1}: {ve}\")\n",
    "            print(\"Skipping to the next question...\\n\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Unexpected error for question {index + 1}: {e}\")\n",
    "            print(\"Skipping to the next question...\\n\")\n",
    "\n",
    "\n",
    "# Run evaluations\n",
    "run_evaluations_from_csv(input_csv_path, output_csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Formatted averages saved to /Users/taha/Desktop/rag/test_data_naive/_results__evaluation_naive_semantic_gradient.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "file_path = '/Users/taha/Desktop/rag/test_data_naive/_evaluation_naive_semantic_gradient.csv'  # Replace with the path to your CSV file\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# List of numeric columns to calculate averages\n",
    "numeric_columns = [\n",
    "    'Token Count', 'Total Cost (USD)', 'Completion Tokens',\n",
    "    'Number of Retrieved documents', 'Response time',\n",
    "    'answer_relevancy', 'context_precision', 'context_recall',\n",
    "    'faithfulness', 'BleuScore', 'RougeScore'\n",
    "]\n",
    "\n",
    "# Calculate the mean for each numeric column\n",
    "averages = df[numeric_columns].mean()\n",
    "\n",
    "# Formatting the averages according to your requirements\n",
    "formatted_averages = {\n",
    "    'Token Count': f\"{averages['Token Count']:.0f}\",  # No decimal places\n",
    "    'Total Cost (USD)': f\"{averages['Total Cost (USD)']:.5f}\",  # Keep as is\n",
    "    'Completion Tokens': f\"{averages['Completion Tokens']:.0f}\",  # No decimal places\n",
    "    'Number of Retrieved documents': f\"{averages['Number of Retrieved documents']}\",  # Keep as is\n",
    "    'Response time': f\"{averages['Response time']:.2f}\",  # One decimal place\n",
    "    'answer_relevancy': f\"{averages['answer_relevancy']:.4f}\",  # Four decimal places\n",
    "    'context_precision': f\"{averages['context_precision']:.4f}\",  # Four decimal places\n",
    "    'context_recall': f\"{averages['context_recall']:.4f}\",  # Four decimal places\n",
    "    'faithfulness': f\"{averages['faithfulness']:.4f}\",  # Four decimal places\n",
    "    'BleuScore': f\"{averages['BleuScore']:.4f}\",  # Four decimal places\n",
    "    'RougeScore': f\"{averages['RougeScore']:.4f}\"  # Four decimal places\n",
    "}\n",
    "\n",
    "# Convert formatted averages to a DataFrame for saving\n",
    "formatted_averages_df = pd.DataFrame([formatted_averages])\n",
    "\n",
    "# Define the output file path by adding \"results_\" prefix\n",
    "output_file_path = os.path.join(\n",
    "    os.path.dirname(file_path), \n",
    "    f\"_results_{os.path.basename(file_path)}\"\n",
    ")\n",
    "\n",
    "# Save the formatted averages to CSV\n",
    "formatted_averages_df.to_csv(output_file_path, index=False)\n",
    "print(f\"[INFO] Formatted averages saved to {output_file_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
