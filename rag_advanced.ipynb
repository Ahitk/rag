{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced RAG\n",
    "\n",
    "#### Problem: her sorguda farkli kategori retrieve edilince bellekte üstüne ekliyor, dolasiyla farkli kategorilerden data alabiliyor soru degistikce, vector database her seferinde hafizayi silmeli!\n",
    "###### Bütüm kodta tutarlilik kontrolü yap, mesela hersey cevabi \"answer\" olarak dönmeli, fronend icin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Evime bir TV alacagim ve bir telkom ürünüyle kullanmak istiyorum, ne tavsiye edersin?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data directory\n",
    "###### data klasörünün altinda 8 ana kategörü olmali, tam olarak isimler uyusmali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory containing the rag data\n",
    "data_directory = \"/Users/taha/Desktop/rag/data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import chromadb\n",
    "import asyncio\n",
    "import gc\n",
    "import tiktoken\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "from langchain.document_loaders import DirectoryLoader, TextLoader\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain_core.prompts import ChatPromptTemplate, HumanMessagePromptTemplate, FewShotChatMessagePromptTemplate, PromptTemplate\n",
    "from langchain.load import dumps, loads\n",
    "from langchain.schema import Document\n",
    "from operator import itemgetter\n",
    "from typing import Literal, List, Tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load API Keys from environment variables\n",
    "load_dotenv()  # Load environment variables from a .env file\n",
    "\n",
    "# Retrieve API keys from environment variables\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "LANGCHAIN_API_KEY = os.getenv(\"LANGCHAIN_API_KEY\")  # This key is loaded but not used in the code\n",
    "\n",
    "# Initialize the chat model and embedding model\n",
    "# ChatOpenAI is used to interact with the OpenAI GPT model, and OpenAIEmbeddings is used for generating embeddings for documents\n",
    "model = ChatOpenAI(model=\"gpt-4o\", api_key=OPENAI_API_KEY)\n",
    "embedding = OpenAIEmbeddings(api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model max token limit\n",
    "MAX_TOKEN_LENGTH = 3000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Summarizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load summarizing chain with \"refine\" method to reduce token size\n",
    "summarize_chain = load_summarize_chain(model, chain_type=\"refine\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "\n",
    "num_tokens_from_string(question, \"cl100k_base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Token count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_token_count(docs, question, prompt):\n",
    "    \"\"\"\n",
    "    If the total token count for the RAG chain exceeds the limit, summarize only the retrieved documents.\n",
    "\n",
    "    Args:\n",
    "        docs (list): List of documents to check for token limits and summarize if needed.\n",
    "        question (str): The original question to include in token count.\n",
    "        prompt (str): The prompt template to include in token count.\n",
    "        max_token_length (int): The maximum number of tokens allowed before summarization.\n",
    "\n",
    "    Returns:\n",
    "        list: Summarized documents or original documents based on token limit.\n",
    "    \"\"\"\n",
    "    # Calculate token counts for different components\n",
    "    prompt_tokens = num_tokens_from_string(prompt.format(context=\"dummy\", question=question), \"cl100k_base\")\n",
    "    question_tokens = num_tokens_from_string(question, \"cl100k_base\")\n",
    "    docs_tokens = sum([num_tokens_from_string(doc.page_content, \"cl100k_base\") for doc in docs])\n",
    "    \n",
    "    # Total token count including prompt, question, and documents\n",
    "    total_tokens = prompt_tokens + question_tokens + docs_tokens\n",
    "    #print(f\"Token count (prompt): {prompt_tokens}\")\n",
    "    #print(f\"Token count (question): {question_tokens}\")\n",
    "    #print(f\"Token count (retrieved documents): {docs_tokens}\")\n",
    "    #print(f\"Total token count (for RAG chain): {total_tokens}\")\n",
    "    \n",
    "   \n",
    "    return total_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cos similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate cosine similarity between two vectors\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    \"\"\"\n",
    "    Computes the cosine similarity between two vectors.\n",
    "    \n",
    "    Parameters:\n",
    "    - vec1 (np.ndarray): The first vector.\n",
    "    - vec2 (np.ndarray): The second vector.\n",
    "    \n",
    "    Returns:\n",
    "    - float: The cosine similarity between vec1 and vec2.\n",
    "    \"\"\"\n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    norm_vec1 = np.linalg.norm(vec1)\n",
    "    norm_vec2 = np.linalg.norm(vec2)\n",
    "    return dot_product / (norm_vec1 * norm_vec2) if (norm_vec1 and norm_vec2) else 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Routing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logical Routing\n",
    "\n",
    "#### 8 Kategoriden birine atiyor, datacategory icerigine göre. Belki biraz daha genisletilebilir, daha uygun kategori atamasi icin.\n",
    "\n",
    "###### ESKI NOT DEGERLENDIR: Routing mantigi calismadi retriever'i sadece ilk seferde filtreliyor, her seferinde chroma ya gömüyü ve hepsini ariyor.\n",
    "###### chain invoke etmeden retriever cagrildigi yerde filtreleme olabilir. Bunu dene!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data model\n",
    "class RouteQuery(BaseModel):\n",
    "    \"\"\"Route a user question to the most relevant datacategory.\"\"\"\n",
    "\n",
    "    datacategory: Literal[\"vertrag_rechnung_ihre_daten_kundencenter_login-daten_rechnung_lieferstatus\", \n",
    "                          \"hilfe_stoerungen_stoerungen_selbst_beheben_melden_status_verfolgen\",\n",
    "                          \"mobilfunk_tarife_optionen_mobiles-internet_mailbox_esim_sim-karten\",\n",
    "                          \"internet_telefonie:_ausbau,_sicherheit,_einstellungen,_bauherren,_glasfaser_und_wlan\",\n",
    "                          \"tv_magentatv_streaming-dienste_magentatv_jugendschutz_pins\",\n",
    "                          \"magentains_kombi-pakete_mit_magentains_vorteil_und_treuebonus\",\n",
    "                          \"apps_dienste_e-mail_magenta_apps_voicemail_app_mobilityconnect\",\n",
    "                          \"geraete_zubehoer_anleitungen_fuer_smartphones_tablets_telefone_router_receiver\"] = Field(\n",
    "        ...,\n",
    "        description=\"Given a user question choose which datacategory would be most relevant for answering their question\",\n",
    "    )\n",
    "\n",
    "# LLM with function call \n",
    "structured_model = model.with_structured_output(RouteQuery)\n",
    "\n",
    "# Prompt \n",
    "system = \"\"\"You are an expert at routing user questions to the appropriate data category.\n",
    "\n",
    "Based on the help category the question is referring to, route it to the relevant data category. \n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Define router \n",
    "router = prompt | structured_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_route(result):\n",
    "    # Kategorileri ve ilgili alt dizinleri bir sözlükte tanımlayın\n",
    "    category_map = {\n",
    "        \"vertrag_rechnung_ihre_daten_kundencenter_login-daten_rechnung_lieferstatus\": \"Vertrag & Rechnung\",\n",
    "        \"hilfe_stoerungen_stoerungen_selbst_beheben_melden_status_verfolgen\": \"Hilfe bei Störungen\",\n",
    "        \"mobilfunk_tarife_optionen_mobiles-internet_mailbox_esim_sim-karten\": \"Mobilfunk\",\n",
    "        \"internet_telefonie:_ausbau,_sicherheit,_einstellungen,_bauherren,_glasfaser_und_wlan\": \"Internet & Telefonie\",\n",
    "        \"tv_magentatv_streaming-dienste_magentatv_jugendschutz_pins\": \"TV\",\n",
    "        \"magentains_kombi-pakete_mit_magentains_vorteil_und_treuebonus\": \"MagentaEINS\",\n",
    "        \"apps_dienste_e-mail_magenta_apps_voicemail_app_mobilityconnect\": \"Apps & Dienste\",\n",
    "        \"geraete_zubehoer_anleitungen_fuer_smartphones_tablets_telefone_router_receiver\": \"Geräte & Zubehör\"\n",
    "    }\n",
    "    \n",
    "    # Datacategory'yi küçült ve sözlükte ara, yoksa \"Others\" döner\n",
    "    return category_map.get(result.datacategory.lower(), \"Others\")\n",
    "\n",
    "full_chain = router | RunnableLambda(choose_route)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TV\n",
      "/Users/taha/Desktop/rag/data/TV\n"
     ]
    }
   ],
   "source": [
    "data_directory = \"/Users/taha/Desktop/rag/data\"\n",
    "\n",
    "sub_directory = full_chain.invoke({\"question\": question})\n",
    "print(sub_directory)\n",
    "\n",
    "specific_directory = os.path.join(data_directory, sub_directory)\n",
    "print(specific_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retriever with filter\n",
    "\n",
    "#### Problem: Birkac farkli kategoriden sorgu yapildiginda o kategorileri hafizada tutuyor ve her seferinden üstüne ekliyor retriever ile gelenlerin.\n",
    "##### ama sadece belli bir kategori filtresi ile calistirmak yeterli context saglamiyor, baska yerlerde de ilgili soru icin gerekli belge olabiliyor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DenseX denemesi yapiyorum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'data/TV/https_www_telekom_de_magenta_tv_online_tv.txt'}, page_content='Source URL: https://www.telekom.de/magenta-tv/online-tv\\n\\nQuestion: Sie haben noch kein MagentaTV?\\nAnswer: Ein großartiges Fernsehvergnügen zu Hause oder unterwegs – das genießen Sie mit der Telekom und Online-TV. Nutzen Sie dafür entweder unserenTV-Receiver, dieMagentaTV Oneoder dieMagentaTV App. Profitieren Sie von zahlreichen komfortablen Funktionen, die Ihr Online-TV-Erlebnis besonders machen:\\n\\n'), Document(metadata={'source': 'data/TV/https_www_telekom_de_magenta_tv.txt'}, page_content='Source URL: https://www.telekom.de/magenta-tv\\n\\nQuestion: Was ist der Unterschied zwischen MagentaTV Smart und MagentaTV Basic?\\nAnswer: Beide Tarife bieten Ihnen ein großes Angebot an Serien und Filmen sowie Zugangsmöglichkeiten zu weiteren Streaming-Diensten. BeiMagentaTV Smartsteht Ihnen im Gegensatz zu MagentaTV Basic eine besonders große Auswahl an öffentlich-rechtlichen sowie privaten Sendern in HD zur Verfügung. Als besonderes Highlight ist RTL+ Premium bei MagentaTV Smart inklusive. Außerdem ermöglicht Ihnen MagentaTV Smart die Nutzung aller Funktionen der MagentaTV App zu Hause und unterwegs sowie 100 Stunden Cloud-Speicher für Ihre Aufnahmen. MagentaTV Basic kann nur zu Hause und nur mit derMagentaTV One, demMagentaTV Stickund der AppleTV 4K genutzt werden. Für Aufnahmen stehen bei MagentaTV Basic 50 Stunden Cloud Speicher zur Verfügung. Zusätzlich genießen Sie mit MagentaTV Smart folgende Vorteile:\\n• Nutzung zu Hause und unterwegs\\n• Nutzung auf 5 Geräten mit bis zu 3 Streams gleichzeitig\\n• Cloud-Speicher für Aufnahmen\\n\\nQuestion: Was genau ist MagentaTV?\\nAnswer: MagentaTV ist dasTV- & Streaming-Angebotder Telekom. Mit diesem Dienst empfangen Sie zahlreiche Fernsehsender und haben außerdem Zugriff auf eine einzigartige Auswahl von Serien, Filmen, Shows und Dokus über MagentaTV+ sowie auf RTL+ Premium für die Tarife MagentaTV Smart, MagentaTV SmartStream und MagentaTV MegaStream. Mit verschiedenen Zusatz-Paketen gestalten Sie Ihr MagentaTV Angebot individuell. Doch nicht nur das: MagentaTV bündelt Ihr gesamtes Fernseh-Erlebnis. Mit nur einer Oberfläche haben Sie Zugriff auf das TV-Programm, auf viele Inhalte aus MagentaTV+ sowie auf Ihre Konten von Netflix, Disney+, Amazon Prime Video, DAZN, WOW oder anderen Streaming-Diensten und Partnern.Streaming-Diensten und Partnern. Mit MagentaSport gestalten Sie Ihr MagentaTV-Angebot individuell.\\nDarüber hinaus profitieren Sie von zahlreichen Funktionen:\\nSo verpassen Sie nichts, auch wenn Sie mal später einschalten. Fernsehen, Filme online schauen und vieles mehr - MagentaTV bietet Ihnen immer die beste Unterhaltung.\\n• Persönliche Schnellstartleiste: Richten Sie sich Ihre persönliche Schnellstartleiste mit den Content Diensten ein, die Sie nutzen.\\n• MagentaTV Sprachassistent: Steuern Sie die Suche, die Lautstärkeregelung und weitere Funktionen bequem per Sprache.\\n• Cloud Recorder: Speichern Sie bis zu 100 Stunden an Aufnahmen in der Cloud ab und rufen diese auch von unterwegs auf\\n• Weitere Komfort-Funktionen bei Nutzung von MagentaTV mit der MagentaTV One oder dem MagentaTV Stick, z.B. Replay.\\n\\nQuestion: Wie viele Sender sind bei MagentaTV inklusive?\\nAnswer: Mit MagentaTV empfangen Sie mit den meisten Tarifen über 180 TV-Sender, davon über 150 in HD. Mit dem Tarif MagentaTV Basic können Sie über 180 TV-Sender, davon über 100 in HD, nutzen. Zum Programm gehören unter anderem Das Erste, ZDF, die Dritten Programme und Privatsender wie RTL, ProSieben, SAT.1 sowie viele weitere Sender. Mit verschiedenen zubuchbaren Optionen können Sie die Sendervielfalt sogar noch vergrößern.MagentaSportbietet Ihnen beispielsweise imLive-Sport-Streamtolle Unterhaltung aus Eishockey, Basketball, Fußball und weiteren Sportarten.\\n\\nQuestion: Was ist MagentaTV Flex und MagentaTV Smart Flex?\\nAnswer: Bei MagentaTV Flex und MagentaTV Smart Flex können SieMagentaTV auch unabhängig vom Internetanbietererleben. Profitieren Sie von einer kurzen Mindestvertragslaufzeit mit monatlicher Kündbarkeit. Mit der mobilen App haben Sie Ihr persönliches Fernseherlebnis immer mit dabei. Egal ob zu Hause oder unterwegs – auf dem Smartphone, Tablet, Laptop und via MagentaTV Stick, Apple TV (ab 4.\\xa0Generation), MagentaTV One oder Amazon Fire TV Stick auf dem Fernseher sowie auf vielen Smart TV-Geräten. Sie empfangen über 100 TV-Sender in HD und haben außerdem kostenlosen Zugriff auf eine große Vielfalt an Serien, Filmen, Dokus und Shows über MagentaTV+(ehemals Megathek). Mit verschiedenen Zusatz-Paketen wie MagentaSport oder demTV-Paket Familygestalten Sie Ihr MagentaTV ganz individuell.\\n\\nQuestion: Für welche Geräte ist MagentaTV Smart geeignet?\\nAnswer: Auf dem Fernseher ist MagentaTV mit MagentaTV One, MagentaTV Stick, Amazon Fire TV und direkt auf Ihrem Samsung Smart TV (ab Modelljahr 2018), LG Smart TV (ab webOS 5) oder Android TV von Sony, Philips, Xiaomi u.v.m. (ab Android OS Version 7.1) nutzbar.\\nDaneben ist MagentaTV Smart auf Smartphone oder Tablet via App (Android, iOS) und perBrowserverfügbar.\\nMit dem Tarif MagentaTV Basic kann MagentaTV nur mitMedia Receiver, wie der MagentaTV One, MagentaTV Stick oder Apple TV 4K genutzt werden. Das Programmieren von Aufnahmen für die Nutzung von Leih- und Kauffilmen ist auch per App (Android, iOS) möglich.\\n\\nQuestion: Welche Funktionen bietet MagentaTV?\\nAnswer: Mit MagentaTV profitieren Sie von zahlreichen Funktionen (einige davon nur bei Nutzung über MagentaTV One oder MagentaTV Stick):\\n• Aufnahmefunktion:Ihre Lieblingssendung oder -serien können Sie ganz einfach einmalig oder auch fortlaufend aufnehmen und zu einem beliebigen Zeitpunkt anschauen.\\n• Timeshift:Unterbrechen Sie das laufende Programm und setzten Sie es zu einem späteren Zeitpunkt fort. Zeitversetztes Fernsehen war noch nie so einfach.\\n• Restart:Springen Sie bei ausgewählten Inhalten zurück oder schauen Sie sie einfach ganz von vorne. Sie bestimmen bei laufenden Sendungen selbst, wann es los- und weitergeht.\\n• Replay:Spielen Sie ausgewählte Sendungen bis zu sieben Tage nach der Ausstrahlung erneut ab. Diese Funktion steht nicht bei allen Sendern bzw. allen Sendungen zur Verfügung.\\n• Übergreifende Suche:Mithilfe dieser Funktion finden Sie Ihre Lieblingsinhalte schnell und einfach. Egal, ob Fernsehen oder On-Demand-Inhalte.\\n• MagentaTV Sprachassistent:Steuern Sie die Suche, die Lautstärkeregelung und weitere Funktionen bequem per Sprache.\\n\\n'), Document(metadata={'source': 'data/TV/youtube_Telekom hilft News： Die neue Oberfläche von MagentaTV.txt'}, page_content='Question:\\nMit welchen Geräten kann das neue Magenta TV genutzt werden?\\n\\nAnswer:\\nQuizfrage: Was ist besser als Magenta TV? Die Antwort ist das neue Magenta TV. Wir haben das Menü intuitiver und übersichtlicher gestaltet. Es ist die ideale Kombination aus Fernsehen und Streaming, für zu Hause oder unterwegs. Das neue design ist simple und intuitiv, und kann individuell angepasst werden. Sie können das Hauptmenü selbst sortieren und durch grüne Haken sehen, welche Inhalte kostenlos angeboten werden.  Das neue Magenta TV kann am besten mit dem Magenta TV 1 oder dem Magenta TV-Stick genutzt werden. Für bestehende Nutzer, deren App sich verändert hat, keine Sorge - Sie können diese App weiterhin nutzen. Wenn Sie jedoch das neue Magenta TV nutzen möchten, benötigen Sie die neue Magenta TV-Elle. Wählen Sie den passenden Magenta TV-Tarif und genießen Sie alle Vorteile der neuen Plattform. Rufen Sie uns an unter 0800-3303000 für tolle Angebote. Ein wichtiger Hinweis für Mieter: Ab dem 1. Juli 2024 darf Kabelfernsehen nicht mehr auf die Nebenkosten umgelegt werden. Entscheiden Sie sich jetzt für das neue Magenta TV und Sie sind zukunftssicher.\\n\\n'), Document(metadata={'source': 'data/TV/youtube_Telekom hilft News： Installation der MagentaTV App an eurem Smart TV.txt'}, page_content='Question:\\nWelche Schritte sind notwendig, um die Magenta TV-App auf meinem Samsung oder Android TV zu nutzen?\\n\\nAnswer:\\nHallo zusammen, ich bin Thomas vom Telekom-Hilft-Team. In diesem Video erkläre ich, wie Sie Magenta TV auf Ihrem Samsung TV oder Android TV nutzen können, ohne dafür ein Ressieber zu benötigen. Sie benötigen lediglich einen Telekom-Account mit gebuchtem Magenta TV-Tarif, der die Nutzung zu Hause und unterwegs ermöglicht. Die Magenta TV-App läuft auf allen Samsung-Geräten mit dem Betriebssystem Tizen von 2017 bis heute und auf allen Smart-TVs mit Android 7, 8 oder 9. Geben Sie einfach \"Magenta TV\" in die Suchleiste Ihres Fernsehers ein und laden Sie die App. Um sie zu starten, melden Sie sich mit Ihrem Telekom-Account an. Magenta TV Smart bietet zahlreiche Möglichkeiten, einschließlich Live-TV mit über 50 HD-Kanälen, Zugang zu Mediatheken wie ARD, ZDF und Pro-7-Sat-1 und Video-Load. Zusätzlich ermöglicht die App, Sendungen neu zu starten oder zu pausieren und bietet 50 Stunden Cloud-Speicher für Aufnahmen. Bis zu drei Nutzer können gleichzeitig über die App auf Magenta TV zugreifen. Viel Spaß beim Fernsehen!\\n\\n'), Document(metadata={'source': 'data/TV/https_www_telekom_de_magenta_tv_geraete_magenta_tv_one.txt'}, page_content='Source URL: https://www.telekom.de/magenta-tv/geraete/magenta-tv-one\\n\\nQuestion: Was ist die MagentaTV One (2. Gen.)?\\nAnswer: Die MagentaTV One (2. Gen.) ist unsere Premium TV-Box, mit der wir Ihnen ein noch besseres TV-Erlebnis bieten möchten. Die Box lässt sich einfach sowie flexibel über WLAN oder LAN installieren und ist äußerst leistungsstark. Mit der hochwertig verarbeiteten Fernbedienung benutzen Sie das Gerät schnell und intuitiv. Die MagentaTV One (2. Gen.) ermöglicht Ihnen komfortabel Zugriff auf die ganze Vielfalt des Entertainments: MagentaTV, Streaming-Dienste, Mediatheken und Apps. Einfach eins für alles.\\n\\nQuestion: Was ist das Besondere an der MagentaTV One (2. Gen.)?\\nAnswer: Die MagentaTV One (2. Gen.) ist die Premium TV-Box für ein über\\xadra\\xadgendes MagentaTV Erlebnis und vereint klassisches Fernsehen mit der großen Vielfalt an Streaming-Diensten, Mediatheken sowie zahlreichen Apps über den Google Play Store. Die hochwertige Fernbedienung ermöglicht eine komfortable und intuitive Nutzung von Fernsehen sowie Inhalten auf Abruf. Durch ihren schnellen Quad-Core-Prozessor und den großen Arbeitsspeicher ist die MagentaTV (2. Gen.) One äußerst leistungsstark, dabei aber energieeffizient. Die TV-Box unterstützt Full HD,4K Ultra HD, HDR, Dolby Vision, Dolby Atmosund bietet Ihnen dadurch eine brillante Qualität in Bild und Ton. Installieren Sie die MagentaTV One (2. Gen.) besonders einfach und schließen Sie diese flexibel über WLAN oder LAN an. Die Installation erfolgt unabhängig vom Internetanbieter oder bequem mit einem Festnetzanschluss der Telekom.\\n\\nQuestion: Was sind die Unterschiede zwischen MagentaTV One (2. Gen.) und dem Vorgängermodell?\\nAnswer: Die MagentaTV One (2. Gen.) ist ausschließlich auf das neue MagentaTV ausgerichtet und optimiert worden, daher ist sie ausschließlich mit MagentaTV 2.0 Tarifen kompatibel. Indessen ist das Vorgängermodell auch mit älteren MagentaTV Tarifen (ab Ende 2020) kompatibel. Der größte funktionale Unterschied zwischen den beiden Modellen liegt in der Fernbedienung. Die MagentaTV One (2. Gen.) besitzt eine Premium Fernbedienung mit leuchtenden Tasten, wobei die Tastenbeleuchtung nur bei ausreichend Dunkelheit und Bewegung aktiviert wird. Darüber hinaus hat die Premium Fernbedienung ein besonders hochwertiges Design und zusätzliche Tasten für ein noch komfortableres MagentaTV Erlebnis. Beispielsweise können Sie mit der TV-Taste jederzeit von überall direkt ins laufende TV-Programm schalten oder mit der Sterntaste schnell die persönlichen Lieblings-Apps starten. Damit Sie zukünftig noch mehr Apps installieren können, hat die MagentaTV One (2. Gen.) doppelt so viel Speicherplatz erhalten. Außerdem unterstützt das neue Modell nun Wi-Fi 6 und Bluetooth 5 während das Vorgängermodell nur bis einschließlich Wi-Fi 5 und Bluetooth 4.2 unterstützt.\\n\\nQuestion: Wie kann ich MagentaTV One (2. Gen.) nutzen?\\nAnswer: Die Voraussetzung für die Nutzung vonMagentaTVmit der MagentaTV One (2. Gen.) ist der Abschluss eines neuenMagentaTV Tarifes(z. B.MagentaTV Smart 2.0). Darüber hinaus benötigen Sie eine bestehende Internet\\xadverbindung, um die Angebote von MagentaTV auf Ihrem Gerät zu sehen. Wir empfehlen Ihnen mindestens 10 MBit/s verfügbare Band\\xadbreite. Für Ihre Internet\\xadverbindung gelten die Bedingungen des jeweiligen Internet\\xadanbieters. Nutzen Sie die MagentaTV One (2. Gen.) über das Mobilfunk-Datennetz, erfolgt die Belastung des Daten\\xadvolumens beim jeweiligen Mobilfunk-Anbieter. Die MagentaTV One (2. Gen.) basiert auf dem Betriebssystem Android TV der Firma Google LLC. Daher ist es notwendig, dass Sie den Google Nutzungs\\xadbedingungen, der Google Daten\\xadschutz\\xaderklärung sowie den Google Play Nutzungs\\xadbedingungen zustimmen. Möchten Sie bestimmte Google Dienste wie den Google Play Store in Anspruch nehmen, benötigen Sie ein Google Konto. Zudem setzt die Nutzung der MagentaTV One (2. Gen.) eine verfügbare Steckdose mit Strom und einen Fernseher mit HDMI-Eingang voraus.\\n\\nQuestion: Welche Inhalte kann ich mit der MagentaTV One (2. Gen.) sehen?\\nAnswer: Verfügen Sie über einen MagentaTV 2.0 Tarif, genießen Sie mit der MagentaTV One (2. Gen.) über 150 TV-Senderin HD und haben die Möglichkeit, die TV-Vielfalt durch verschiedeneZubuchoptionenzu erweitern. MitMagentaTV+(ehemals Megathek), das in allen MagentaTV Tarifen immer enthalten ist, stehen zahlreiche Serien, Filme, Shows und Dokus auf Abruf zur Verfügung. Dazu haben Sie mit der MagentaTV One (2. Gen.) Zugriff auf viele Streaming-Dienste (z. B. Netflix, Prime Video, WOW, DAZN), Mediatheken und zahlreiche Apps im Google Play Store. Für die Dienste benötigen Sie gegebenenfalls separate Verträge. Die Nutzung von Sky über die MagentaTV One (2. Gen.) ist in Verbindung mit dem Streaming-Angebot WOW und der WOW App möglich. Anders verhält es sich mit dem Sky-Abo (inkl. SkyQ). Ob über Sky direkt gebucht oder ein als MagentaTV Produkt erworbenes Jahresabo von Sky – diese können Sie nicht mit MagentaTV One (2. Gen.) empfangen.\\n\\nQuestion: Was ist im Lieferumfang der MagentaTV One (2. Gen.) enthalten?\\nAnswer: Der Lieferumfang umfasst neben der MagentaTV One (2. Gen.) die passende Fernbedienung mit Batterien sowie ein Netzteil, ein Netzwerkkabel und eine Bedienungsanleitung. Damit installieren Sie die MagentaTV One (2. Gen.) direkt, um das TV-Erlebnis zu genießen.\\n\\nQuestion: Wo ist die MagentaTV One (2. Gen.) erhältlich?\\nAnswer: Die MagentaTV One (2. Gen.) ist überall dort erhältlich, wo es MagentaTV gibt: im Telekom Shop, unter 0800 33 03000, online oder im Handel – perfekt in Kombination mit einem MagentaTV Tarif, wie z. B. demMagentaZuhause M mit MagentaTV Smart 2.0.\\n\\nQuestion: Kann ich die neue Premium Fernbedienung auch an der 1. Generation der MagentaTV One verwenden?\\nAnswer: Die Kopplung ist zwar technisch möglich, jedoch recht umständlich. Von der Kombination wird abgeraten, da hierbei diverse Tasten nicht unterstützt werden (Spulen, Aufnehmen, Restart, Sterntaste) und die Tastenbeleuchtung nicht konfiguriert werden kann (auch wenn sie funktioniert). Zudem ist die Premium Fernbedienung nicht separat erhältlich, sondern ausschließlich bei einer MagentaTV One (2. Gen.) inklusive.\\n\\nQuestion: Wie kann ich den Magenta Sprachassistenten auf meiner MagentaTV One (2. Gen.) nutzen?\\nAnswer: Einfach die Mikrofon-Taste der Fernbedienung drücken und sagen, was der Magenta Sprachassistent bei MagentaTV machen soll, z.B. „Suche die Tagesschau“, „Schalte auf RTL“, „Öffne Netflix“ u.v.m.Alle Sprachbefehle\\n\\n')]\n"
     ]
    }
   ],
   "source": [
    "# İlk olarak, eski vectorstore ve retriever nesnelerini temizleyelim\n",
    "vectorstore = None\n",
    "retriever = None\n",
    "\n",
    "# Çöp toplama işlemi\n",
    "gc.collect()\n",
    "\n",
    "def load_summaries(data_directory):\n",
    "    summary_files = glob.glob(os.path.join(data_directory, '**/_summary.txt'), recursive=True)\n",
    "    summaries = {}\n",
    "    \n",
    "    for file in summary_files:\n",
    "        with open(file, 'r') as f:\n",
    "            content = f.read()\n",
    "            \n",
    "        chunks = content.split(\"=== Chunk ===\")\n",
    "        \n",
    "        for chunk in chunks:\n",
    "            if \"File path:\" in chunk and \"File summary:\" in chunk:\n",
    "                try:\n",
    "                    lines = chunk.split('\\n')\n",
    "                    file_path_line = [line for line in lines if \"File path:\" in line]\n",
    "                    summary_line = [line for line in lines if \"File summary:\" in line]\n",
    "\n",
    "                    if file_path_line and summary_line:\n",
    "                        file_path = file_path_line[0].split(\"File path:\")[1].strip()\n",
    "                        summary_text = summary_line[0].split(\"File summary:\")[1].strip()\n",
    "                        summaries[file_path] = summary_text\n",
    "                except IndexError:\n",
    "                    print(f\"Warning: Skipping chunk due to formatting issues in file: {file}\")\n",
    "\n",
    "    return summaries\n",
    "\n",
    "# Load summaries\n",
    "summaries = load_summaries(specific_directory)\n",
    "\n",
    "def find_closest_summaries(question, summaries, embedding, top_n=5):\n",
    "    \"\"\"\n",
    "    Finds the closest summary files based on the user's question using cosine similarity.\n",
    "    \n",
    "    Parameters:\n",
    "    - question (str): The user's question.\n",
    "    - summaries (dict): Dictionary where keys are file paths and values are summary texts.\n",
    "    - embedding (object): Embedding model used to get vector representations.\n",
    "    - top_n (int): The number of top closest summaries to retrieve.\n",
    "    \n",
    "    Returns:\n",
    "    - list: List of file paths to the top_n closest summaries.\n",
    "    \"\"\"\n",
    "    # Embed the question\n",
    "    query_embedding = embedding.embed_query(question)\n",
    "    \n",
    "    # List to hold (file_path, similarity) tuples\n",
    "    similarities = []\n",
    "    \n",
    "    # Calculate similarity for each summary\n",
    "    for file_path, summary in summaries.items():\n",
    "        summary_embedding = embedding.embed_query(summary)\n",
    "        \n",
    "        # Ensure embeddings are 1D vectors for cosine similarity computation\n",
    "        query_embedding = np.squeeze(query_embedding)\n",
    "        summary_embedding = np.squeeze(summary_embedding)\n",
    "        \n",
    "        # Compute similarity\n",
    "        similarity = cosine_similarity(query_embedding, summary_embedding)\n",
    "        similarities.append((file_path, similarity))\n",
    "    \n",
    "    # Sort by similarity and get the top_n results\n",
    "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "    return [file_path for file_path, _ in similarities[:top_n]]\n",
    "\n",
    "# Retrieve closest summary files\n",
    "closest_files = find_closest_summaries(question, summaries, embedding)\n",
    "\n",
    "# Load documents from the closest file paths\n",
    "def load_documents_from_paths(paths):\n",
    "    docs = []\n",
    "    for path in paths:\n",
    "        with open(path, 'r') as f:\n",
    "            content = f.read()\n",
    "        docs.append(Document(page_content=content, metadata={'source': path}))\n",
    "    return docs\n",
    "\n",
    "# Load documents\n",
    "docs = load_documents_from_paths(closest_files)\n",
    "\n",
    "print(docs)\n",
    "\n",
    "# Create vectorstore and retriever\n",
    "vectorstore = Chroma.from_documents(documents=docs, embedding=embedding)\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### orjinal filtreli retriever -  yedek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1443 documents.\n",
      "Filtered 489 documents.\n",
      "Vectorstore created from filtered documents.\n",
      "bound=VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x1480811f0>)\n"
     ]
    }
   ],
   "source": [
    "'''# İlk olarak, eski vectorstore ve retriever nesnelerini temizleyelim\n",
    "vectorstore = None\n",
    "retriever = None\n",
    "\n",
    "# Çöp toplama işlemi\n",
    "gc.collect()\n",
    "\n",
    "# Load documents from the specified directory\n",
    "loader = DirectoryLoader(data_directory, glob=\"**/*.txt\", loader_cls=TextLoader)\n",
    "docs = loader.load()  # Load all text documents matching the pattern\n",
    "print(f\"Loaded {len(docs)} documents.\")  # Debug print\n",
    "\n",
    "# Ensure all documents have metadata\n",
    "for doc in docs:\n",
    "    if 'full_path' not in doc.metadata:\n",
    "        doc.metadata['full_path'] = doc.metadata.get('source', 'unknown')\n",
    "\n",
    "# Manually filter documents based on metadata\n",
    "filtered_docs = [doc for doc in docs if doc.metadata.get('full_path', '').startswith(specific_directory)]\n",
    "print(f\"Filtered {len(filtered_docs)} documents.\")  # Debug print\n",
    "\n",
    "# Create a Chroma vector store from the filtered documents and embeddings\n",
    "if filtered_docs:\n",
    "    vectorstore = Chroma.from_documents(documents=filtered_docs, embedding=embedding)\n",
    "    print(\"Vectorstore created from filtered documents.\")\n",
    "\n",
    "    # Set up the retriever using the filtered vector store\n",
    "    retriever = vectorstore.as_retriever()\n",
    "else:\n",
    "    print(\"No documents found to create a vectorstore.\")\n",
    "    retriever = None'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retriever without filter\n",
    "##### Orjinal - yedek retriever, filtreleme yok. Bütün kategorilerden context ceker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def initialize_vectorstore(directory):\\n    \"\"\"\\n    Initializes a vector store from the documents found in the specified directory.\\n    This function performs the following steps:\\n    1. Loads text documents from the given directory using a DirectoryLoader.\\n    2. Creates embeddings for the loaded documents using a predefined embedding model.\\n    3. Initializes a Chroma vector store with these embeddings.\\n    \\n    Parameters:\\n        directory (str): The path to the directory containing text files to be processed.\\n    \\n        \\n    Returns:\\n        vectorstore (Chroma): A Chroma vector store object containing the embeddings of the documents.\\n        docs (List[Document]): A list of Document objects loaded from the specified directory.\\n        \\n    \"\"\"\\n    \\n    # Load documents from the specified directory using DirectoryLoader\\n    loader = DirectoryLoader(directory, glob=\"**/*.txt\", loader_cls=TextLoader)\\n    docs = loader.load()  # Load all text documents matching the pattern\\n    \\n    # Create a Chroma vector store from the loaded documents and embeddings\\n    vectorstore = Chroma.from_documents(documents=docs, embedding=embedding)\\n    \\n    return vectorstore, docs\\n\\n# Initialize the vector store and document list\\nvectorstore, docs = initialize_vectorstore(data_directory)\\n\\n# Set up the retriever using the vector store\\nretriever = vectorstore.as_retriever()'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''def initialize_vectorstore(directory):\n",
    "    \"\"\"\n",
    "    Initializes a vector store from the documents found in the specified directory.\n",
    "    This function performs the following steps:\n",
    "    1. Loads text documents from the given directory using a DirectoryLoader.\n",
    "    2. Creates embeddings for the loaded documents using a predefined embedding model.\n",
    "    3. Initializes a Chroma vector store with these embeddings.\n",
    "    \n",
    "    Parameters:\n",
    "        directory (str): The path to the directory containing text files to be processed.\n",
    "    \n",
    "        \n",
    "    Returns:\n",
    "        vectorstore (Chroma): A Chroma vector store object containing the embeddings of the documents.\n",
    "        docs (List[Document]): A list of Document objects loaded from the specified directory.\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # Load documents from the specified directory using DirectoryLoader\n",
    "    loader = DirectoryLoader(directory, glob=\"**/*.txt\", loader_cls=TextLoader)\n",
    "    docs = loader.load()  # Load all text documents matching the pattern\n",
    "    \n",
    "    # Create a Chroma vector store from the loaded documents and embeddings\n",
    "    vectorstore = Chroma.from_documents(documents=docs, embedding=embedding)\n",
    "    \n",
    "    return vectorstore, docs\n",
    "\n",
    "# Initialize the vector store and document list\n",
    "vectorstore, docs = initialize_vectorstore(data_directory)\n",
    "\n",
    "# Set up the retriever using the vector store\n",
    "retriever = vectorstore.as_retriever()'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Main telekom prompt\n",
    "\n",
    "##### To-do: Kategorilerde uygun cevap bulunamazsa nasil bir tepki verecek bunu tanimla.\n",
    "##### Bu prompt daha efektif hale getirilebilir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the template for generating an answer based on context and a question\n",
    "telekom_template = \"\"\"You are an assistant for question-answering tasks for telekom.de help, providing answers to Telekom customers or potential customers. \n",
    "Use the following pieces of retrieved context to answer the question. \n",
    "If you don't know the answer or if the provided documents do not contain relevant information, simply say that unfortunately, you cannot assist with this question and please visit www.telekom.de/hilfe for further assistance. \n",
    "Use up to four sentences and keep the answer concise.\n",
    "Question: {question}\n",
    "Context: {context}\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "prompt_telekom = ChatPromptTemplate.from_template(telekom_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Query Translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Multi-query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer: Evde kullanmak üzere bir TV almayı düşünüyorsanız, Telekom'un MagentaTV hizmetini tavsiye ederim. MagentaTV ile, büyük ekran TV'nizde üstün kalitede televizyon deneyimi yaşayabilirsiniz. Bunun için MagentaTV One cihazını veya Telekom'un TV-Receiver'ını kullanabilirsiniz. Daha fazla bilgi için lütfen [www.telekom.de/hilfe](www.telekom.de/hilfe) adresini ziyaret edin.\n",
      "\n",
      "Generated Questions:\n",
      "1. Hangi TV markaları telkom ürünleriyle uyumlu çalışıyor ve önerir misiniz?\n",
      "2. Telkom ürünleriyle uyumlu olan TV modelleri hakkında bilgi verebilir misiniz?\n",
      "3. TV alırken telkom ürünleriyle entegrasyonu en iyi olan marka veya model hangisidir?\n",
      "4. Telkom ürünleriyle uyumlu çalışan TV'ler arasında en iyi seçenek hangisidir?\n",
      "5. Telkom ürünleriyle sorunsuz bir şekilde entegre olan TV modelleri hakkında önerileriniz nelerdir?\n",
      "\n",
      "Sources:\n",
      "Source document: /Users/taha/Desktop/rag/data/Geräte & Zubehör/youtube_Kennt ihr schon unsere Videoberatung？ Hier ist MagentaService Live.txt\n",
      "\n",
      "Cosine Similarity: 0.8077\n",
      "\n",
      "Question:\n",
      "Möchten Sie sich unser neues Telekom Hilfe-Video für eine persönliche Beratung ansehen?\n",
      "\n",
      "Answer:\n",
      "Suchen Sie etwas Neues wie Fernsehen, Smartphone oder ein smartes Zuhause? Für eine schnelle und unkomplizierte persönliche Beratung, schauen Sie sich unser neues Telekom Hilfe-Video an.\n",
      "\n",
      "Source document: /Users/taha/Desktop/rag/data/Geräte & Zubehör/https_www_telekom_de_zuhause_geraete_und_zubehoer_media_receiver.txt\n",
      "\n",
      "Cosine Similarity: 0.7955\n",
      "\n",
      "Source URL: https://www.telekom.de/zuhause/geraete-und-zubehoer/media-receiver\n",
      "\n",
      "Question: Welcher Receiver eignet sich für den Empfang von MagentaTV und digitales Fernsehen?\n",
      "Answer: Mit unserer Premium TV-BoxMagentaTV Onesind Sie bestens für MagentaTV ausgerüstet.\n",
      "\n",
      "Question: Kann ich einen AV-Receiver zwischen meinem TV-Receiver und meinem Fernseher anschließen?\n",
      "Answer: Ja, das geht. Viele unserer Modelle können Sie mit einem AV-Receiver verbinden. Voraussetzung ist, dass der AV-Receiver und der Fernseher mindestens einen HDMI 2.0 Anschluss besitzen. Für die Wiedergabe von UHD-Medien müssen beide Geräte HDCP 2.2 unterstützen.\n",
      "\n",
      "Question: Ist der TV-Receiver mit Airties Geräten kompatibel?\n",
      "Answer: Ja, die Media Receiver der Telekom lassen sich als WLAN-Client mit Airties Geräten verbinden.\n"
     ]
    }
   ],
   "source": [
    "# Template for Generating Alternative Questions\n",
    "template = \"\"\"You are an AI language model assistant. Your task is to generate five \n",
    "different versions of the given user question to retrieve relevant documents from a vector \n",
    "database. By generating multiple perspectives on the user question, your goal is to help\n",
    "the user overcome some of the limitations of the distance-based similarity search. \n",
    "Provide these alternative questions separated by newlines. Original question: {question}\"\"\"\n",
    "\n",
    "# Create a prompt template for generating multiple perspectives of the user's question\n",
    "prompt_perspectives = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# Define a pipeline for generating alternative queries\n",
    "generate_queries = (\n",
    "    prompt_perspectives \n",
    "    | ChatOpenAI(temperature=0) \n",
    "    | StrOutputParser() \n",
    "    | (lambda x: x.split(\"\\n\"))  # Split the generated output into individual queries\n",
    ")\n",
    "\n",
    "# Asynchronous function to print generated queries\n",
    "async def print_generated_queries(question):\n",
    "    \"\"\"\n",
    "    Generates and prints multiple search queries related to the input question.\n",
    "    \n",
    "    Parameters:\n",
    "    - question (str): The input query for which related search queries are generated.\n",
    "    \"\"\"\n",
    "    queries = generate_queries.invoke({\"question\": question})\n",
    "    print(\"\\nGenerated Questions:\")\n",
    "    for q in queries:\n",
    "        print(f\"{q}\")\n",
    "\n",
    "def get_unique_union(documents):\n",
    "    \"\"\"\n",
    "    Returns a unique union of retrieved documents.\n",
    "\n",
    "    This function takes a list of lists of documents, flattens it, and removes duplicates\n",
    "    to ensure each document is unique.\n",
    "\n",
    "    Args:\n",
    "        documents (list of lists): A list where each element is a list of documents.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of unique documents.\n",
    "    \"\"\"\n",
    "    # Flatten the list of lists of documents\n",
    "    flattened_docs = [dumps(doc) for sublist in documents for doc in sublist]\n",
    "    # Remove duplicates by converting to a set and then back to a list\n",
    "    unique_docs = list(set(flattened_docs))\n",
    "    # Deserialize the documents back into their original form\n",
    "    return [loads(doc) for doc in unique_docs]\n",
    "\n",
    "# Define the retrieval chain, which includes generating queries, retrieving documents, and removing duplicates\n",
    "retrieval_chain = generate_queries | retriever.map() | get_unique_union\n",
    "\n",
    "# Retrieve multiple documents based on the input question\n",
    "multi_query_docs = retrieval_chain.invoke({\"question\": question})\n",
    "\n",
    "\n",
    "def format_docs(docs, query_embedding):\n",
    "    \"\"\"\n",
    "    Formats the retrieved documents with their source and cosine similarity score.\n",
    "\n",
    "    This function takes a list of documents and formats them to include the source of each document\n",
    "    and its cosine similarity to the query embedding.\n",
    "\n",
    "    Args:\n",
    "        docs (list): A list of documents retrieved from the database.\n",
    "        query_embedding (numpy array): The embedding of the user's query.\n",
    "\n",
    "    Returns:\n",
    "        str: A formatted string containing the source, similarity score, and content of each document.\n",
    "    \"\"\"\n",
    "    # Initialize a set to track unique sources\n",
    "    unique_sources = set()\n",
    "    formatted_docs = []\n",
    "\n",
    "    for doc in docs:\n",
    "        # Retrieve the source of the document from its metadata\n",
    "        source = doc.metadata.get(\"source\")\n",
    "        # Check if the source is unique\n",
    "        if source and source not in unique_sources:\n",
    "            unique_sources.add(source)\n",
    "            # Compute the embedding of the document's content\n",
    "            document_embedding = embedding.embed_query(doc.page_content)\n",
    "            # Calculate cosine similarity between the query and document embeddings\n",
    "            similarity = cosine_similarity(query_embedding, document_embedding)\n",
    "            # Use a placeholder message if the document content is empty\n",
    "            content = doc.page_content.strip() or \"This document content is empty.\"\n",
    "            # Format the document's source, similarity score, and content\n",
    "            formatted_docs.append(\n",
    "                f\"Source document: {source}\\n\\nCosine Similarity: {similarity:.4f}\\n\\n{content}\"\n",
    "            )\n",
    "\n",
    "    # Join the formatted documents into a single string\n",
    "    return \"\\n\\n\".join(formatted_docs)\n",
    "\n",
    "# Define a retrieval and generation (RAG) chain for processing the question and context\n",
    "rag_chain = (\n",
    "    {\"context\": retrieval_chain, \"question\": itemgetter(\"question\")} \n",
    "    | prompt_telekom\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "async def retrieve_and_format_docs(question):\n",
    "    \"\"\"\n",
    "    Asynchronously retrieves and formats documents for the given question.\n",
    "\n",
    "    This function retrieves documents relevant to the user's question and formats them with their\n",
    "    source information and cosine similarity scores.\n",
    "\n",
    "    Args:\n",
    "        question (str): The user's question.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the answer and formatted documents.\n",
    "    \"\"\"\n",
    "    # Compute the embedding for the user's question\n",
    "    query_embedding = embedding.embed_query(question)\n",
    "    # Format the retrieved documents with their cosine similarity scores\n",
    "    formatted_docs = format_docs(multi_query_docs, query_embedding)\n",
    "    \n",
    "    try:\n",
    "        # Attempt to retrieve an answer using the RAG chain asynchronously\n",
    "        answer = await rag_chain.invoke({\"context\": formatted_docs, \"question\": question})\n",
    "    except TypeError:\n",
    "        # Fallback in case of TypeError, invoke the RAG chain synchronously\n",
    "        answer = rag_chain.invoke({\"context\": formatted_docs, \"question\": question})\n",
    "    \n",
    "    # Return the answer and the formatted documents\n",
    "    return answer, formatted_docs\n",
    "\n",
    "async def main():\n",
    "    \"\"\"\n",
    "    The main asynchronous function to run the complete flow.\n",
    "\n",
    "    This function handles the process of generating alternative queries, retrieving and formatting\n",
    "    documents, and printing the final answer along with the source documents.\n",
    "    \"\"\"\n",
    "   \n",
    "    # Retrieve and format documents, then get the answer\n",
    "    answer, source_docs = await retrieve_and_format_docs(question)\n",
    "\n",
    "    get_token_count(multi_query_docs, question, prompt_telekom)\n",
    "    # Print the final answer\n",
    "    print(\"\\nAnswer:\", answer)\n",
    "     # Generate and print alternative queries\n",
    "    await print_generated_queries(question)\n",
    "    # Print the source documents used for the answer\n",
    "    print(\"\\nSources:\")\n",
    "    print(source_docs)\n",
    "\n",
    "# Execute the main function\n",
    "await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### RAG-Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer: Evinizde ses komutları ile yönlendirebileceğiniz ürünler arıyorsanız, Telekom'un Magenta SmartHome ürünlerini tavsiye ederim. Magenta SmartHome, Alexa Skill ile entegre olarak çalışabilir ve böylece ışıkları açıp kapatmak, sıcaklığı ayarlamak veya radyoyu açmak gibi birçok işlemi sesli komutlarla gerçekleştirebilirsiniz. Daha fazla bilgi ve detaylı kurulum için www.telekom.de/smarte-produkte/smart-home adresini ziyaret edebilirsiniz.\n",
      "\n",
      "Generated Questions:\n",
      "1. En iyi ses komutlu ev aletleri\n",
      "2. Evde kullanabileceğim akıllı cihazlar\n",
      "3. Sesli komutlarla kontrol edilebilen ev ürünleri\n",
      "4. Evde sesle yönlendirilebilen cihazlar önerileri\n",
      "\n",
      "Sources:\n",
      "Source: /Users/taha/Desktop/rag/data/Geräte & Zubehör/youtube_Digitale Organisation mit iOS-Geräten – Adressbuch, Kalender und Co. I Telekom Senioren-Akademie.txt\n",
      "Fusion Score: 0.0640\n",
      "Cosine Similarity: 0.7491\n",
      "Content: Question:\n",
      "Gibt es eine Möglichkeit, mit Siri eine Erinnerung für bestimmte Ereignisse oder Termine zu erstellen?\n",
      "\n",
      "Answer:\n",
      "Willkommen zur Zusammenfassung unserer Telekom-Signion-Akademie. In unseren Live-Seminaren und aufgezeichneten Kursen helfen wir Ihnen, die digitale Welt zu entdecken und sich damit vertraut zu machen. In dieser Lektion lernen Sie, wie Sie Ihr Smartphone oder Tablet nutzen können, um Ihren Alltag zu organisieren. Mithilfe kleiner Geschichten erklären wir die Verwendung von Kalender und Kontakten auf Ihrem Gerät.\n",
      "\n",
      "Wir zeigen Ihnen, wie Sie Adressen und Geburtstage speichern, Ihren Kalender für tägliche Erinnerungen nutzen und Notizen für Dinge wie Einkaufslisten erstellen können. Zudem stellen wir Ihnen Siri vor, den Sprachassistenten von Apple, der Ihnen dabei hilft, Funktionen auf Ihrem iPhone oder iPad auszuführen. Siri kann Ihnen das Wetter verraten, Nachrichten senden, Timer stellen und sogar den Weg nach Hause zeigen.\n",
      "\n",
      "All diese Funktionen sind auf allen Ihren Apple-Geräten verfügbar und werden automatisch synchronisiert. Für weitere Informationen über unsere Kurse können Sie unsere Website www.telekom.de/Synjuan besuchen. Wir sind ständig bemüht, unser Angebot zu verbessern und freuen uns über Ihr Feedback. Vielen Dank, dass Sie bei unserem Kurs mitgemacht haben. Bis zum nächsten Mal!\n",
      "\n",
      "\n",
      "\n",
      "Source: /Users/taha/Desktop/rag/data/Geräte & Zubehör/https_www_telekom_de_hilfe_geraete_zubehoer_smart_home_hilfe_zur_einrichtung_von_smart_home_einrichten_von_regeln_und_szenen_schaltersteuerung_erklaerung.txt\n",
      "Fusion Score: 0.0331\n",
      "Cosine Similarity: 0.7329\n",
      "Content: Source URL: https://www.telekom.de/hilfe/geraete-zubehoer/smart-home/hilfe-zur-einrichtung-von-smart-home/einrichten-von-regeln-und-szenen/schaltersteuerung-erklaerung\n",
      "Telekom > Hilfe & Service > Geräte & Zubehör > SmartHome: > Geräte & Apps > Hilfe > zur > Einrichtung > von > Magenta > SmartHome > Einrichten > von > Regeln und Szenen > Weitere > Steuerung > Magenta > SmartHome\n",
      "\n",
      "Question: Was bedeutet Weitere Steuerung bei Magenta SmartHome?\n",
      "Answer: Über \"Weitere Steuerung\" in \"Automatisierung hinzufügen\" können der Szene Schalter zugeordnet werden. Die Szene kann dann über diesen Schalter aktiviert/ deaktiviert werden.Folgende Schalter werden unterstützt: Wandtaster Aufputz, 4-Tasten Fernbedienung Bitron Home und 4-Tasten Handsender HomeMatic. Wird einer dieser Schalter der Szene oder mehrere hinzugefügt, dann kann man mit ihnen die Szene manuell ein- oder ausschalten.\n",
      "\n",
      "\n",
      "\n",
      "Source: /Users/taha/Desktop/rag/data/Geräte & Zubehör/https_www_telekom_de_smarte_produkte_smart_home_alexa_skill.txt\n",
      "Fusion Score: 0.0331\n",
      "Cosine Similarity: 0.7476\n",
      "Content: Source URL: https://www.telekom.de/smarte-produkte/smart-home/alexa-skill\n",
      "\n",
      "Question: Was können Sie mit dem SmartHome Alexa Skill tun?\n",
      "Answer: An-/Ausschalten\n",
      "Dimmen\n",
      "Farbe einstellen\n",
      "„Deckenlampe“ steht hierbei beispielhaft für den von dir vergebenen Gerätenamen.\n",
      "Mithilfe der Steuerung von Zwischensteckern lassen sich zahlreiche Geräte, wie zum Beispiel eine Stehlampe, die Kaffeemaschine, das Radio oder der Ventilator, einfach mit einem Sprachbefehl ein- und ausschalten.\n",
      "Tischlampe anschalten\n",
      "Radio einschalten\n",
      "„Tischlampe” und „Radio” stehen hierbei beispielhaft für den von dir vergebenen Gerätenamen.\n",
      "Temperatur einstellen\n",
      "Einstellen einer bestimmten Gradzahl\n",
      "Temperatur verändern\n",
      "Erhöhen oder Senken der Temperatur\n",
      "Temperatur abfragen\n",
      "Abfragen der Raumtemperatur\n",
      "„Wohnzimmer” steht hierbei beispielhaft für den von dir vergebenen Namen des Thermostates.\n",
      "Rollläden steuern\n",
      "„Rollladen” steht hier beispielhaft für den von dir vergebenen Gerätenamen.\n",
      "Szene Energie sparen\n",
      "Szene Gemütlicher Abend\n",
      "\n",
      "Question: Wie kann ich die Benennung der Geräte anpassen?\n",
      "Answer: • Jeden Namen nur einmal verwenden\n",
      "• Einen gebräuchlichen und kurzen Namen benutzen\n",
      "• Auf Abkürzungen, Sonderzeichen, Zahlen, lange Namen und Emojis verzichten\n",
      "\n",
      "Question: Wie kann ich vom SmartHome Alexa Skill komplett auf den Magenta SmartHome Alexa Skill wechseln?\n",
      "Answer: • den SmartHome Skill zu deaktivieren\n",
      "• die vorhandenen Geräte aus deiner Alexa App zu entfernen.\n",
      "\n",
      "\n",
      "\n",
      "Source: /Users/taha/Desktop/rag/data/Geräte & Zubehör/https_www_telekom_de_hilfe_geraete_zubehoer_smart_home_nutzung_und_funktionen_von_smart_home_das_alarmsytem_von_smart_home_geraete_alarmsystem_kompatibel.txt\n",
      "Fusion Score: 0.0331\n",
      "Cosine Similarity: 0.7588\n",
      "Content: Source URL: https://www.telekom.de/hilfe/geraete-zubehoer/smart-home/nutzung-und-funktionen-von-smart-home/das-alarmsytem-von-smart-home/geraete-alarmsystem-kompatibel\n",
      "Telekom > Hilfe & Service > Geräte & Zubehör > SmartHome: > Geräte & Apps > Nutzung und Funktionen > von > Magenta > SmartHome > Das > Alarmsytem > von > Magenta > SmartHome\n",
      "\n",
      "Question: Mit welchen Geräten funktioniert mein Alarmsystem?\n",
      "Answer: Für Ihr Alarmsystem können Sie die Sirene, aber auch den Rauchmelder von Bitron Home nutzen. Zudem werden automatisch sowohl alle Leuchten, die an einen Dimmer angeschlossen sind, als auch alle Philips HUE Lampen angeschaltet und die Kamera beginnt mit der Aufzeichnung.\n",
      "Haben Sie einen Rauchmelder von Bitron Home, dann wird dieser in Ihrem Alarmsystem automatisch als Alarmgeber genutzt.Sie wählen nur die für Sie sicherheitsrelevanten Sensoren aus, bei deren Impuls das Alarmsystem Alarm geben soll.\n",
      "Um Fehlalarme zu vermeiden, empfehlen wir den Bewegungsmelder der Außenkamera im Alarmsystem auszuschließen. Die Sensitivität dieses integrierten Bewegungsmelders ist so hoch, dass Alarme bereits bei Lichtreflexionen ausgelöst werden.\n",
      "\n",
      "\n",
      "\n",
      "Source: /Users/taha/Desktop/rag/data/Geräte & Zubehör/https_www_telekom_de_hilfe_geraete_zubehoer_smart_home_nutzung_und_funktionen_von_smart_home_nutzung_der_smart_home_app_und_der_home_base_sprachsteuerung_app_aenderung_geraetenamen.txt\n",
      "Fusion Score: 0.0331\n",
      "Cosine Similarity: 0.7485\n",
      "Content: Source URL: https://www.telekom.de/hilfe/geraete-zubehoer/smart-home/nutzung-und-funktionen-von-smart-home/nutzung-der-smart-home-app-und-der-home-base/sprachsteuerung-app-aenderung-geraetenamen\n",
      "Telekom > Hilfe & Service > Geräte & Zubehör > SmartHome: > Geräte & Apps > Nutzung und Funktionen > von > Magenta > SmartHome > Nutzung > der > Magenta > SmartHome > App und der > Home > Base > Sprachsteuerung > Magenta > SmartHome > App\n",
      "\n",
      "Question: Wie kann ich Geräte, Szenen oder die Temperatur von Räumen per Sprache steuern, nachdem ich die Namen in der Magenta SmartHome App geändert habe?\n",
      "Answer: Wenn Sie den Namen von einem Gerät, einer Szene oder einem Raum geändert haben, können Sie natürlich auch weiterhin die Sprachsteuerung verwenden, bspw. über Google Home oder Amazon Alexa.\n",
      "Sie müssen nach der Namensänderung zunächst lediglich in der App des jeweiligen Smart Speakers die Geräte- oder Raumübersicht aktualisieren. Ohne eine Aktualisierung ist die Steuerung per Sprache mit den neu vergebenen Namen nicht möglich. Nach der Aktualisierung kann die Steuerung wieder wie gewohnt erfolgen.\n",
      "\n",
      "\n",
      "\n",
      "Source: /Users/taha/Desktop/rag/data/Geräte & Zubehör/https_www_telekom_de_hilfe_geraete_zubehoer_smart_home_nutzung_und_funktionen_von_smart_home_nutzung_der_smart_home_app_und_der_home_base_magenta_smarthome_datenverschluesselung.txt\n",
      "Fusion Score: 0.0320\n",
      "Cosine Similarity: 0.7177\n",
      "Content: Source URL: https://www.telekom.de/hilfe/geraete-zubehoer/smart-home/nutzung-und-funktionen-von-smart-home/nutzung-der-smart-home-app-und-der-home-base/magenta-smarthome-datenverschluesselung\n",
      "Telekom > Hilfe & Service > Geräte & Zubehör > SmartHome: > Geräte & Apps > Nutzung und Funktionen > von > Magenta > SmartHome > Nutzung > der > Magenta > SmartHome > App und der > Home > Base > Sichere > Datenverschlüsselung\n",
      "\n",
      "Question: Erfolgt eine sichere Datenverschlüsselung, wenn ich Magenta SmartHome nutze?\n",
      "Answer: Die Kommunikation zwischen SmartHome-App und QIVICON Home Base (QHB) läuft verschlüsselt über ein Backend-System ab. Sofern man sich im gleichen Netz wie die QHB befindet, kann man auch lokal auf diese zugreifen.Die Datenbank des Backends ist ebenfalls verschlüsselt, so dass niemand die Inhalte direkt abfragen kann. Es werden keine Schaltzustände oder andere Daten der Kundeninstallation im Backend gespeichert. Diese werden einzig in der QHB vorgehalten.Die Autorisierung erfolgt im gesamten QIVICON Eco-System über OAuth2. Das OAuth-Token kann nur mit korrektem Nutzernamen und Passwort erzeugt werden. Ohne ein gültiges Token hat niemand (auch kein Admin) Zugriff auf die angeschlossenen Geräte.\n",
      "Die QIVICON-Plattform ist von der Telekom Konzernsicherheit überprüft und unterliegt den gleichen Auflagen, wie alle anderen Konzernprodukte. Beispielsweise wurde bei der Integration der Homematic-Produkte nicht nur die standardmäßig vorgesehene Verschlüsselung mit dem Default-Schlüssel von eq3 verwendet, sondern es wird bei der Registrierung der Home Base ein individueller Schlüssel für jeden Kunden generiert, der für die Verschlüsselung der Funkkommunikation verwendet wird. Das bedeutet aber auch, dass die Geräte fix mit der jeweiligen Homebase verbunden sind und bei einem eventuellen Außerbetriebnehmen erst sauber getrennt werden müssen, sonst kann niemand sie jemals wieder verwenden.Kommunikation: Die Kommunikation erfolgt per HTTPS mit OAuth2-Authentifizierung entweder direkt zwischen App und Home Base oder mit dem dazwischen geschalteten Backend. Sämtliche Kommunikation ist Event-basiert. Es werden u. a. WebSockets verwendet.\n",
      "\n",
      "\n",
      "\n",
      "Source: /Users/taha/Desktop/rag/data/Geräte & Zubehör/https_www_telekom_de_smarte_produkte_smart_home.txt\n",
      "Fusion Score: 0.0320\n",
      "Cosine Similarity: 0.7308\n",
      "Content: Source URL: https://www.telekom.de/smarte-produkte/smart-home\n",
      "\n",
      "Question: Wie sicher sind Smart Home Systeme?\n",
      "Answer: Das unabhängige IT-Sicherheitsinstitut AV-Test zeichnete SmartHome der Telekom mit dem Testurteil „Sicher“ aus. Außerdem speichern wir alle Daten Ihres Smart Homes ausnahmslos in deutschen Rechenzentren mit höchsten Sicherheitsstandards. Damit Ihr Smart Home umfangreich vor Angriffen aus dem Internet und Hackern geschützt ist, sollten Sie bei den Einstellungen dennoch Folgendes beachten:\n",
      "• Richten Sie starke Passwörter (auch für Ihre WLAN-Verbindung) ein.\n",
      "• Achten Sie auf ein (mit WPA2) verschlüsseltes WLAN.\n",
      "• Wenn Sie mehrere Apps verwenden: Vergeben Sie unterschiedliche und sichere Passwörter.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the template for generating multiple search queries based on a single input query.\n",
    "template = \"\"\"You are a helpful assistant that generates multiple search queries based on a single input query. \\n\n",
    "Generate multiple search queries related to: {question} \\n\n",
    "Output (4 queries):\"\"\"\n",
    "prompt_rag_fusion = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# Create a chain for generating four related search queries\n",
    "generate_fusion_queries = (\n",
    "    prompt_rag_fusion \n",
    "    | ChatOpenAI(temperature=0)\n",
    "    | StrOutputParser() \n",
    "    | (lambda x: x.split(\"\\n\"))\n",
    ")\n",
    "\n",
    "async def print_generated_fusion_queries(question):\n",
    "    \"\"\"\n",
    "    Generates and prints multiple search queries related to the input question.\n",
    "    \n",
    "    Parameters:\n",
    "    - question (str): The input query for which related search queries are generated.\n",
    "    \"\"\"\n",
    "    queries = generate_fusion_queries.invoke({\"question\": question})\n",
    "    print(\"\\nGenerated Questions:\")\n",
    "    for q in queries:\n",
    "        print(f\"{q}\")\n",
    "\n",
    "# Function for Reciprocal Rank Fusion (RRF)\n",
    "def reciprocal_rank_fusion(results: list[list], k=60):\n",
    "    \"\"\"\n",
    "    Applies Reciprocal Rank Fusion (RRF) to combine multiple lists of ranked documents.\n",
    "    \n",
    "    Parameters:\n",
    "    - results (list[list]): A list of lists where each inner list contains ranked documents.\n",
    "    - k (int): An optional parameter for the RRF formula, default is 60.\n",
    "    \n",
    "    Returns:\n",
    "    - list: A list of tuples where each tuple contains a document and its fused score.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize a dictionary to store the fused scores for each unique document\n",
    "    fused_scores = {}\n",
    "\n",
    "    # Iterate through each list of ranked documents\n",
    "    for docs in results:\n",
    "        # Iterate through each document in the list, with its rank (position in the list)\n",
    "        for rank, doc in enumerate(docs):\n",
    "            # Serialize the document to a string format to use as a key\n",
    "            doc_str = dumps(doc)\n",
    "            # Initialize the document's score if not already present\n",
    "            if doc_str not in fused_scores:\n",
    "                fused_scores[doc_str] = 0\n",
    "            # Update the document's score using the RRF formula: 1 / (rank + k)\n",
    "            fused_scores[doc_str] += 1 / (rank + k)\n",
    "\n",
    "    # Sort documents based on their fused scores in descending order\n",
    "    reranked_results = [\n",
    "        (loads(doc), score)\n",
    "        for doc, score in sorted(fused_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    ]\n",
    "\n",
    "    # Return the reranked results as a list of tuples\n",
    "    return reranked_results\n",
    "\n",
    "# Create a retrieval chain that generates queries, retrieves documents, and applies RRF\n",
    "retrieval_chain_rag_fusion = generate_queries | retriever.map() | reciprocal_rank_fusion\n",
    "fusion_docs = retrieval_chain_rag_fusion.invoke({\"question\": question})\n",
    "\n",
    "# Function to get embeddings for a document's content\n",
    "async def get_document_embeddings(doc):\n",
    "    \"\"\"\n",
    "    Retrieves the embeddings for a document's content asynchronously.\n",
    "    \n",
    "    Parameters:\n",
    "    - doc (Document): The document object whose content embeddings are to be retrieved.\n",
    "    \n",
    "    Returns:\n",
    "    - np.ndarray: The embeddings of the document's content.\n",
    "    \"\"\"\n",
    "    return embedding.embed_query(doc.page_content)\n",
    "\n",
    "# Function to format fusion_docs as a readable string with similarity scores\n",
    "async def format_fusion_docs_with_similarity(fusion_docs):\n",
    "    \"\"\"\n",
    "    Formats the fusion documents with their scores and cosine similarity to the question.\n",
    "    \n",
    "    Parameters:\n",
    "    - fusion_docs (list[tuple]): A list of tuples containing documents and their scores.\n",
    "    \n",
    "    Returns:\n",
    "    - str: A formatted string containing each document's source, fusion score, cosine similarity, and content.\n",
    "    \"\"\"\n",
    "    formatted_docs = []\n",
    "    question_embedding = embedding.embed_query(question)\n",
    "    \n",
    "    for doc, score in fusion_docs:\n",
    "        doc_embedding = await get_document_embeddings(doc)\n",
    "        similarity = cosine_similarity(question_embedding, doc_embedding)\n",
    "        source = doc.metadata.get(\"source\", \"No source\")\n",
    "        content = doc.page_content\n",
    "        formatted_docs.append(f\"Source: {source}\\nFusion Score: {score:.4f}\\nCosine Similarity: {similarity:.4f}\\nContent: {content}\\n\")\n",
    "    \n",
    "    return \"\\n\".join(formatted_docs)\n",
    "\n",
    "\n",
    "# Create a chain that uses context and question to generate an answer\n",
    "rag_chain = (\n",
    "    {\"context\": retrieval_chain_rag_fusion, \"question\": itemgetter(\"question\")} \n",
    "    | prompt_telekom\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Asynchronous function to retrieve and format documents, then get an answer\n",
    "async def retrieve_and_format_docs(question):\n",
    "    \"\"\"\n",
    "    Retrieves and formats documents, then obtains an answer to the question.\n",
    "    \n",
    "    Parameters:\n",
    "    - question (str): The query for which answers and document formats are required.\n",
    "    \n",
    "    Returns:\n",
    "    - tuple: A tuple containing the answer and the formatted documents.\n",
    "    \"\"\"\n",
    "    formatted_docs = await format_fusion_docs_with_similarity(fusion_docs)\n",
    "    \n",
    "    try:\n",
    "        # Attempt to get the answer asynchronously\n",
    "        answer = await rag_chain.invoke({\"context\": formatted_docs, \"question\": question})\n",
    "    except TypeError:\n",
    "        # Fallback to synchronous invocation if asynchronous fails\n",
    "        answer = rag_chain.invoke({\"context\": formatted_docs, \"question\": question})\n",
    "    \n",
    "    return answer, formatted_docs\n",
    "\n",
    "\n",
    "# Main function to run the sequence of operations\n",
    "async def main():\n",
    "    \"\"\"\n",
    "    Main function to execute the entire process: generating queries, retrieving and formatting documents, and getting answers.\n",
    "    \"\"\"\n",
    "    doc_list = [doc for doc, score in fusion_docs]\n",
    "    get_token_count(doc_list, question, prompt_telekom)\n",
    "    \n",
    "    answer, formatted_docs = await retrieve_and_format_docs(question)\n",
    "    print(\"\\nAnswer:\", answer)\n",
    "    await print_generated_fusion_queries(question)\n",
    "    print(\"\\nSources:\")\n",
    "    print(formatted_docs)  # Print the formatted version of fusion_docs with similarity scores\n",
    "\n",
    "# Execute the main function\n",
    "await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step Back\n",
    "\n",
    "###### cosine similarity ve token sayisi eksik sadece calisiyor suan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Few Shot Examples\n",
    "examples = [\n",
    "    {\n",
    "        \"input\": \"Could the members of The Police perform lawful arrests?\",\n",
    "        \"output\": \"what can the members of The Police do?\",\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"Jan Sindel’s was born in what country?\",\n",
    "        \"output\": \"what is Jan Sindel’s personal history?\",\n",
    "    },\n",
    "]\n",
    "\n",
    "# Transform examples into example messages\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"ai\", \"{output}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"You are an expert at world knowledge. Your task is to step back and paraphrase a question to a more generic step-back question, which is easier to answer. Here are a few examples:\"\"\",\n",
    "        ),\n",
    "        few_shot_prompt,\n",
    "        (\"user\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Generate step-back queries\n",
    "generate_queries_step_back = prompt | model | StrOutputParser()\n",
    "step_back_question = generate_queries_step_back.invoke({\"question\": question})\n",
    "\n",
    "print(f\"Original Question: {question}\")\n",
    "print(f\"Step-Back Question: {step_back_question}\")\n",
    "\n",
    "# Response prompt template\n",
    "response_prompt_template = \"\"\"You are an expert of world knowledge. I am going to ask you a question. Your response should be comprehensive and not contradicted with the following context if they are relevant. Otherwise, ignore them if they are not relevant.\n",
    "\n",
    "# Normal Context:\n",
    "{normal_context}\n",
    "\n",
    "# Step-Back Context:\n",
    "{step_back_context}\n",
    "\n",
    "# Original Question: {question}\n",
    "\n",
    "# Answer:\n",
    "\"\"\"\n",
    "response_prompt = ChatPromptTemplate.from_template(response_prompt_template)\n",
    "\n",
    "def get_retrieved_content(retrieved_documents):\n",
    "    \"\"\"Format retrieved documents as a string with source information.\"\"\"\n",
    "    seen_sources = set()\n",
    "    content_list = []\n",
    "    for doc in retrieved_documents:\n",
    "        source = doc.metadata.get('source', 'Unknown')\n",
    "        if source not in seen_sources:\n",
    "            seen_sources.add(source)\n",
    "            content = (\n",
    "                f\"Source: {source}\\n\"\n",
    "                f\"Content:\\n{doc.page_content}\\n\"\n",
    "                \"------------------------------\\n\"\n",
    "            )\n",
    "            content_list.append(content)\n",
    "    return \"\\n\".join(content_list)\n",
    "\n",
    "def format_retrieved_context(query):\n",
    "    \"\"\"Retrieve and format context for the given query.\"\"\"\n",
    "    # Retrieve documents using the 'invoke' method\n",
    "    retrieved_docs = retriever.invoke(query)\n",
    "    return get_retrieved_content(retrieved_docs)\n",
    "\n",
    "# Construct the chain to retrieve and generate the response\n",
    "chain = (\n",
    "    {\n",
    "        \"normal_context\": lambda x: format_retrieved_context(x[\"question\"]),\n",
    "        \"step_back_context\": lambda x: format_retrieved_context(x[\"step_back_question\"]),\n",
    "        \"question\": lambda x: x[\"question\"],\n",
    "    }\n",
    "    | response_prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Execute the chain\n",
    "result = chain.invoke({\"question\": question, \"step_back_question\": step_back_question})\n",
    "\n",
    "# Display the final response\n",
    "print(\"\\nAnswer:\\n\", result)\n",
    "print(\"\\nNormal Context:\\n\", format_retrieved_context(question))\n",
    "print(\"\\nStep-Back Context:\\n\", format_retrieved_context(step_back_question))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Few Shot Examples\n",
    "# This list provides example pairs of input questions and their corresponding step-back questions for model training.\n",
    "examples = [\n",
    "    {\n",
    "        \"input\": \"Could the members of The Police perform lawful arrests?\",\n",
    "        \"output\": \"what can the members of The Police do?\",\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"Jan Sindel’s was born in what country?\",\n",
    "        \"output\": \"what is Jan Sindel’s personal history?\",\n",
    "    },\n",
    "]\n",
    "\n",
    "# Create a prompt template for examples.\n",
    "# This template formats example messages for the model to learn from.\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{input}\"),  # Input from the user\n",
    "        (\"ai\", \"{output}\"),    # Model's response to the input\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create a few-shot prompt template that includes example prompts.\n",
    "# This helps the model understand the context by providing example inputs and outputs.\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    ")\n",
    "\n",
    "# Define the final prompt template.\n",
    "# This includes system instructions and integrates the few-shot prompt.\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"You are an expert at world knowledge. Your task is to step back and paraphrase a question to a more generic step-back question, which is easier to answer. Here are a few examples:\"\"\",\n",
    "        ),\n",
    "        few_shot_prompt,\n",
    "        (\"user\", \"{question}\"),  # Input question from the user\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Generate step-back queries using the defined prompt.\n",
    "# This involves processing the original question to generate a more general query.\n",
    "generate_queries_step_back = prompt | model | StrOutputParser()\n",
    "step_back_question = generate_queries_step_back.invoke({\"question\": question})\n",
    "\n",
    "\n",
    "# Response prompt template\n",
    "# This template is used to generate the final response based on the retrieved context and the original question.\n",
    "response_prompt_template = \"\"\"You are an expert of world knowledge. I am going to ask you a question. Your response should be comprehensive and not contradicted with the following context if they are relevant. Otherwise, ignore them if they are not relevant.\n",
    "\n",
    "# Normal Context:\n",
    "{normal_context}\n",
    "\n",
    "# Step-Back Context:\n",
    "{step_back_context}\n",
    "\n",
    "# Original Question: {question}\n",
    "\n",
    "# Answer:\n",
    "\"\"\"\n",
    "response_prompt = ChatPromptTemplate.from_template(response_prompt_template)\n",
    "\n",
    "def get_retrieved_content(retrieved_documents):\n",
    "    \"\"\"\n",
    "    Format retrieved documents as a string with source information.\n",
    "    \n",
    "    Args:\n",
    "        retrieved_documents (list): List of documents retrieved based on the query.\n",
    "        \n",
    "    Returns:\n",
    "        str: Formatted string containing source and content of retrieved documents.\n",
    "    \"\"\"\n",
    "    seen_sources = set()  # Track unique sources\n",
    "    content_list = []      # List to accumulate formatted content\n",
    "    for doc in retrieved_documents:\n",
    "        source = doc.metadata.get('source', 'Unknown')  # Get source of the document\n",
    "        if source not in seen_sources:\n",
    "            seen_sources.add(source)\n",
    "            content = (\n",
    "                f\"Source: {source}\\n\"\n",
    "                f\"Content:\\n{doc.page_content}\\n\"\n",
    "                \"------------------------------\\n\"\n",
    "            )\n",
    "            content_list.append(content)\n",
    "    return \"\\n\".join(content_list)\n",
    "\n",
    "def format_retrieved_context(query):\n",
    "    \"\"\"\n",
    "    Retrieve and format context for the given query.\n",
    "    \n",
    "    Args:\n",
    "        query (str): The query for which context needs to be retrieved.\n",
    "        \n",
    "    Returns:\n",
    "        str: Formatted string containing context relevant to the query.\n",
    "    \"\"\"\n",
    "    # Retrieve documents using the 'invoke' method\n",
    "    retrieved_docs = retriever.invoke(query)\n",
    "    return get_retrieved_content(retrieved_docs)\n",
    "\n",
    "# Construct the chain to retrieve and generate the response.\n",
    "# This chain combines context retrieval and response generation.\n",
    "chain = (\n",
    "    {\n",
    "        \"normal_context\": lambda x: format_retrieved_context(x[\"question\"]),\n",
    "        \"step_back_context\": lambda x: format_retrieved_context(x[\"step_back_question\"]),\n",
    "        \"question\": lambda x: x[\"question\"],\n",
    "    }\n",
    "    | response_prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Execute the chain to get the final response.\n",
    "result = chain.invoke({\"question\": question, \"step_back_question\": step_back_question})\n",
    "\n",
    "# Display the final response along with normal and step-back contexts.\n",
    "print(\"Answer:\", result)\n",
    "print(f\"\\n\\nOriginal Question: {question}\")\n",
    "print(f\"\\nStep-Back Question: {step_back_question}\")\n",
    "print(\"\\nNormal Context:\\n\", format_retrieved_context(question))\n",
    "print(\"\\nStep-Back Context:\\n\", format_retrieved_context(step_back_question))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### HyDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HyDE document generation\n",
    "template = \"\"\"You are creating professional and customer-focused web page content and texts for a major telecommunications provider like Telekom.de. \n",
    "Your content is very brief, very clear, and informative. Please write a text for the following question\n",
    "Question: {question}\n",
    "text:\"\"\"\n",
    "prompt_hyde = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "generate_docs_for_retrieval = (\n",
    "    prompt_hyde | ChatOpenAI(temperature=0) | StrOutputParser() \n",
    ")\n",
    "\n",
    "# Run HyDE generation\n",
    "try:\n",
    "    hyde_output = generate_docs_for_retrieval.invoke({\"question\": question})\n",
    "    print(f\"HyDE hypothetical answer:\\n{hyde_output.strip()}\\n\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error generating documents for retrieval: {e}\")\n",
    "    raise\n",
    "\n",
    "# Retrieve documents\n",
    "try:\n",
    "    retrieval_chain = generate_docs_for_retrieval | retriever \n",
    "    retrieved_docs = retrieval_chain.invoke({\"question\": question})\n",
    "    \n",
    "    # Print retrieved documents, deduplicated\n",
    "    seen_sources = set()\n",
    "    print(\"Retrieved sources:\")\n",
    "    for doc in retrieved_docs:\n",
    "        source = doc.metadata.get('source', 'Unknown Source')\n",
    "        if source not in seen_sources:\n",
    "            seen_sources.add(source)\n",
    "            print(f\"\\nDocument Source: {source}\")\n",
    "            print(f\"Document Content:\\n{doc.page_content.strip()}\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error retrieving documents: {e}\")\n",
    "    raise\n",
    "\n",
    "# RAG\n",
    "template = \"\"\"Answer the following question based on this context:\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "final_rag_chain = (\n",
    "    prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "try:\n",
    "    final_answer = final_rag_chain.invoke({\"context\": retrieved_docs, \"question\": question})\n",
    "    print(f\"\\nFinal RAG Answer:\\n{final_answer.strip()}\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error generating final RAG answer: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HyDE Document Generation\n",
    "# This section is responsible for creating professional and customer-focused content\n",
    "# for a major telecommunications provider based on a given question.\n",
    "\n",
    "# Define a template for generating content.\n",
    "# The template specifies that the content should be brief, clear, and informative.\n",
    "template = \"\"\"You are creating professional and customer-focused web page content and texts for a major telecommunications provider like Telekom.de. \n",
    "Your content is very brief, very clear, and informative. Please write a text for the following question:\n",
    "Question: {question}\n",
    "text:\"\"\"\n",
    "\n",
    "# Create a prompt template using the defined template.\n",
    "# This template will be used to generate content for a given question.\n",
    "prompt_hyde = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# Define a chain to generate documents for retrieval.\n",
    "# This chain uses the prompt template, a language model, and an output parser.\n",
    "generate_docs_for_retrieval = (\n",
    "    prompt_hyde | ChatOpenAI(temperature=0) | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Run HyDE document generation to produce content for the given question.\n",
    "# The try-except block handles potential errors during document generation.\n",
    "try:\n",
    "    hyde_output = generate_docs_for_retrieval.invoke({\"question\": question})\n",
    "    print(f\"HyDE hypothetical context:\\n{hyde_output.strip()}\\n\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error generating documents for retrieval: {e}\")\n",
    "    raise\n",
    "\n",
    "# Retrieve Documents\n",
    "# This section retrieves documents based on the generated content and prints them.\n",
    "\n",
    "# Define a chain to retrieve documents using the generated content.\n",
    "# The chain combines the document generation process with a retriever.\n",
    "try:\n",
    "    retrieval_chain = generate_docs_for_retrieval | retriever \n",
    "    retrieved_docs = retrieval_chain.invoke({\"question\": question})\n",
    "    \n",
    "    # Print retrieved documents and deduplicate them based on source information.\n",
    "    seen_sources = set()\n",
    "    print(\"Retrieved sources:\")\n",
    "    for doc in retrieved_docs:\n",
    "        source = doc.metadata.get('source', 'Unknown Source')  # Get the source of the document\n",
    "        if source not in seen_sources:\n",
    "            seen_sources.add(source)\n",
    "            print(f\"\\nSource file: {source}\")\n",
    "            print(f\"Document Content:\\n{doc.page_content.strip()}\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error retrieving documents: {e}\")\n",
    "    raise\n",
    "\n",
    "# Define a chain to generate the final answer using the RAG process.\n",
    "# The chain combines the prompt template, a language model, and an output parser.\n",
    "final_rag_chain = (\n",
    "    prompt_telekom\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Generate the final answer using the RAG process.\n",
    "# The try-except block handles potential errors during the final answer generation.\n",
    "try:\n",
    "    final_answer = final_rag_chain.invoke({\"context\": retrieved_docs, \"question\": question})\n",
    "    print(f\"\\nFinal Answer:\\n{final_answer.strip()}\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error generating final RAG answer: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### !!Decomposition\n",
    "###### Calismadi olmadi maalesef, asnwer sadece 3. sorunun cevabini veriyor, stratch den baska kaynakalara bakip cözüm bulmak lazim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define prompts and chains\n",
    "template = \"\"\"You are a helpful assistant that generates multiple sub-questions related to an input question. \\n\n",
    "The goal is to break down the input into a set of sub-problems / sub-questions that can be answered in isolation. \\n\n",
    "Generate multiple search queries related to: {question} \\n\n",
    "Output (3 queries):\"\"\"\n",
    "prompt_decomposition = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# Chain\n",
    "generate_queries_decomposition = ( prompt_decomposition | model | StrOutputParser() | (lambda x: x.split(\"\\n\")))\n",
    "\n",
    "# Run\n",
    "questions = generate_queries_decomposition.invoke({\"question\":question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer recursion\n",
    "template = \"\"\"Here is the question you need to answer:\n",
    "\n",
    "\\n --- \\n {question} \\n --- \\n\n",
    "\n",
    "Here is any available background question + answer pairs:\n",
    "\n",
    "\\n --- \\n {q_a_pairs} \\n --- \\n\n",
    "\n",
    "Here is additional context relevant to the question: \n",
    "\n",
    "\\n --- \\n {context} \\n --- \\n\n",
    "\n",
    "Use the above context and any background question + answer pairs to answer the question: \\n {question}\n",
    "\"\"\"\n",
    "decomposition_prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "def format_qa_pair(question, answer):\n",
    "    \"\"\"Format Q and A pair\"\"\"\n",
    "    \n",
    "    formatted_string = \"\"\n",
    "    formatted_string += f\"Question: {question}\\nAnswer: {answer}\\n\\n\"\n",
    "    return formatted_string.strip()\n",
    "\n",
    "\n",
    "q_a_pairs = \"\"\n",
    "for q in questions:\n",
    "    \n",
    "    rag_chain = (\n",
    "    {\"context\": itemgetter(\"question\") | retriever, \n",
    "     \"question\": itemgetter(\"question\"),\n",
    "     \"q_a_pairs\": itemgetter(\"q_a_pairs\")} \n",
    "    | decomposition_prompt\n",
    "    | model\n",
    "    | StrOutputParser())\n",
    "\n",
    "    answer_decomposition = rag_chain.invoke({\"question\":q,\"q_a_pairs\":q_a_pairs})\n",
    "    q_a_pair = format_qa_pair(q,answer_decomposition)\n",
    "    q_a_pairs = q_a_pairs + \"\\n---\\n\"+  q_a_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-retrieval"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
