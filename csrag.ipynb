{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import time  # Import time to measure response time\n",
    "import streamlit as st\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "from langchain_community.callbacks import get_openai_callback\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "from indexing import get_vectorstore\n",
    "from pprint import pprint\n",
    "import routing\n",
    "\n",
    "from tavily import TavilyClient\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain.docstore.document import Document\n",
    "from typing_extensions import TypedDict\n",
    "from typing import List\n",
    "import initials\n",
    "import prompts\n",
    "\n",
    "\n",
    "### Tavily web search tool\n",
    "tavily_client = TavilyClient(api_key = initials.TAVILY_API_KEY)\n",
    "\n",
    "# Executing question, \n",
    "# qna_search performs a search and returns a str containing an answer to the original query.\n",
    "#web_search_tool = tavily_client.qna_search(question)\n",
    "#print(web_search_tool)\n",
    "\n",
    "### Retrieval Grader\n",
    "# Data model\n",
    "class GradeDocuments(BaseModel):\n",
    "    \"\"\"Binary score for relevance check on retrieved documents.\"\"\"\n",
    "\n",
    "    binary_score: str = Field(description=\"Documents are relevant to the question, 'yes' or 'no'\")\n",
    "\n",
    "### Hallucination Grader\n",
    "# Data model\n",
    "class GradeHallucinations(BaseModel):\n",
    "    \"\"\"Binary score for hallucination present in generation answer.\"\"\"\n",
    "\n",
    "    binary_score: str = Field(\n",
    "        description=\"Answer is grounded in the facts, 'yes' or 'no'\"\n",
    "    )\n",
    "\n",
    "### Answer Grader\n",
    "# Data model\n",
    "class GradeAnswer(BaseModel):\n",
    "    \"\"\"Binary score to assess answer addresses question.\"\"\"\n",
    "\n",
    "    binary_score: str = Field(\n",
    "        description=\"Answer addresses the question, 'yes' or 'no'\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#question = \"Tesla'nin en yeni modeli hangisidir?\"\n",
    "question = \"Evimda kullandigim internetin hizinda problem yasiyorum, kesintiler oluyor, ne yapmaliyim?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings calculated: 0\n",
      "Total documents created: 0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected IDs to be a non-empty list, got 0 IDs",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Vector store ve retriever'i yükle\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m vector_store \u001b[38;5;241m=\u001b[39m \u001b[43mget_vectorstore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitials\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitials\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_directory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitials\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m retriever \u001b[38;5;241m=\u001b[39m vector_store\u001b[38;5;241m.\u001b[39mas_retriever()\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Geri getirme işlevi için yapılandırılmış LLM\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/rag/indexing.py:154\u001b[0m, in \u001b[0;36mget_vectorstore\u001b[0;34m(question, model, data_directory, embedding)\u001b[0m\n\u001b[1;32m    152\u001b[0m summaries \u001b[38;5;241m=\u001b[39m load_summaries(get_specific_directory(question, model, data_directory))\n\u001b[1;32m    153\u001b[0m \u001b[38;5;66;03m# Chroma vektör mağazasını oluşturun\u001b[39;00m\n\u001b[0;32m--> 154\u001b[0m summary_vectorstore \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_chroma_vectorstore\u001b[49m\u001b[43m(\u001b[49m\u001b[43msummaries\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;66;03m# Chroma'dan bir retriever oluşturun\u001b[39;00m\n\u001b[1;32m    156\u001b[0m summary_retriever \u001b[38;5;241m=\u001b[39m summary_vectorstore\u001b[38;5;241m.\u001b[39mas_retriever(search_kwargs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mk\u001b[39m\u001b[38;5;124m\"\u001b[39m: TOP_N})    \n",
      "File \u001b[0;32m~/Desktop/rag/indexing.py:82\u001b[0m, in \u001b[0;36mcreate_chroma_vectorstore\u001b[0;34m(summaries, embedding)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal documents created: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(documents)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# Create Chroma vectorstore from documents\u001b[39;00m\n\u001b[0;32m---> 82\u001b[0m summary_vectorstore \u001b[38;5;241m=\u001b[39m \u001b[43mChroma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m summary_vectorstore\n",
      "File \u001b[0;32m~/Desktop/rag/venv/lib/python3.12/site-packages/langchain_chroma/vectorstores.py:1128\u001b[0m, in \u001b[0;36mChroma.from_documents\u001b[0;34m(cls, documents, embedding, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m texts \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[1;32m   1127\u001b[0m metadatas \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[0;32m-> 1128\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_texts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1129\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtexts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1130\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1132\u001b[0m \u001b[43m    \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1133\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1134\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpersist_directory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpersist_directory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_settings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1136\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1137\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1138\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1139\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/rag/venv/lib/python3.12/site-packages/langchain_chroma/vectorstores.py:1089\u001b[0m, in \u001b[0;36mChroma.from_texts\u001b[0;34m(cls, texts, embedding, metadatas, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[0m\n\u001b[1;32m   1083\u001b[0m         chroma_collection\u001b[38;5;241m.\u001b[39madd_texts(\n\u001b[1;32m   1084\u001b[0m             texts\u001b[38;5;241m=\u001b[39mbatch[\u001b[38;5;241m3\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m batch[\u001b[38;5;241m3\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m [],\n\u001b[1;32m   1085\u001b[0m             metadatas\u001b[38;5;241m=\u001b[39mbatch[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m batch[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   1086\u001b[0m             ids\u001b[38;5;241m=\u001b[39mbatch[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m   1087\u001b[0m         )\n\u001b[1;32m   1088\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1089\u001b[0m     \u001b[43mchroma_collection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1090\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m chroma_collection\n",
      "File \u001b[0;32m~/Desktop/rag/venv/lib/python3.12/site-packages/langchain_chroma/vectorstores.py:557\u001b[0m, in \u001b[0;36mChroma.add_texts\u001b[0;34m(self, texts, metadatas, ids, **kwargs)\u001b[0m\n\u001b[1;32m    551\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_collection\u001b[38;5;241m.\u001b[39mupsert(\n\u001b[1;32m    552\u001b[0m             embeddings\u001b[38;5;241m=\u001b[39membeddings_without_metadatas,  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    553\u001b[0m             documents\u001b[38;5;241m=\u001b[39mtexts_without_metadatas,\n\u001b[1;32m    554\u001b[0m             ids\u001b[38;5;241m=\u001b[39mids_without_metadatas,\n\u001b[1;32m    555\u001b[0m         )\n\u001b[1;32m    556\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 557\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_collection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupsert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    558\u001b[0m \u001b[43m        \u001b[49m\u001b[43membeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[1;32m    559\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    560\u001b[0m \u001b[43m        \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    561\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ids\n",
      "File \u001b[0;32m~/Desktop/rag/venv/lib/python3.12/site-packages/chromadb/api/models/Collection.py:298\u001b[0m, in \u001b[0;36mCollection.upsert\u001b[0;34m(self, ids, embeddings, metadatas, documents, images, uris)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupsert\u001b[39m(\n\u001b[1;32m    268\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    269\u001b[0m     ids: OneOrMany[ID],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    279\u001b[0m     uris: Optional[OneOrMany[URI]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    280\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    281\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Update the embeddings, metadatas or documents for provided ids, or create them if they don't exist.\u001b[39;00m\n\u001b[1;32m    282\u001b[0m \n\u001b[1;32m    283\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;124;03m        None\u001b[39;00m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    292\u001b[0m     (\n\u001b[1;32m    293\u001b[0m         ids,\n\u001b[1;32m    294\u001b[0m         embeddings,\n\u001b[1;32m    295\u001b[0m         metadatas,\n\u001b[1;32m    296\u001b[0m         documents,\n\u001b[1;32m    297\u001b[0m         uris,\n\u001b[0;32m--> 298\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_and_prepare_upsert_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m        \u001b[49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muris\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39m_upsert(\n\u001b[1;32m    303\u001b[0m         collection_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid,\n\u001b[1;32m    304\u001b[0m         ids\u001b[38;5;241m=\u001b[39mids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    308\u001b[0m         uris\u001b[38;5;241m=\u001b[39muris,\n\u001b[1;32m    309\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/rag/venv/lib/python3.12/site-packages/chromadb/api/models/CollectionCommon.py:540\u001b[0m, in \u001b[0;36mCollectionCommon._validate_and_prepare_upsert_request\u001b[0;34m(self, ids, embeddings, metadatas, documents, images, uris)\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_and_prepare_upsert_request\u001b[39m(\n\u001b[1;32m    514\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    515\u001b[0m     ids: OneOrMany[ID],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    531\u001b[0m     Optional[URIs],\n\u001b[1;32m    532\u001b[0m ]:\n\u001b[1;32m    533\u001b[0m     (\n\u001b[1;32m    534\u001b[0m         ids,\n\u001b[1;32m    535\u001b[0m         embeddings,\n\u001b[1;32m    536\u001b[0m         metadatas,\n\u001b[1;32m    537\u001b[0m         documents,\n\u001b[1;32m    538\u001b[0m         images,\n\u001b[1;32m    539\u001b[0m         uris,\n\u001b[0;32m--> 540\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_embedding_set\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    541\u001b[0m \u001b[43m        \u001b[49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muris\u001b[49m\n\u001b[1;32m    542\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    544\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m embeddings \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    545\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m documents \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/rag/venv/lib/python3.12/site-packages/chromadb/api/models/CollectionCommon.py:174\u001b[0m, in \u001b[0;36mCollectionCommon._validate_embedding_set\u001b[0;34m(self, ids, embeddings, metadatas, documents, images, uris, require_embeddings_or_data)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_embedding_set\u001b[39m(\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    154\u001b[0m     ids: OneOrMany[ID],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    172\u001b[0m     Optional[URIs],\n\u001b[1;32m    173\u001b[0m ]:\n\u001b[0;32m--> 174\u001b[0m     valid_ids \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_ids\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_cast_one_to_many_ids\u001b[49m\u001b[43m(\u001b[49m\u001b[43mids\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    175\u001b[0m     valid_embeddings \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    176\u001b[0m         validate_embeddings(\n\u001b[1;32m    177\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_normalize_embeddings(maybe_cast_one_to_many_embedding(embeddings))\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    181\u001b[0m     )\n\u001b[1;32m    182\u001b[0m     valid_metadatas \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    183\u001b[0m         validate_metadatas(maybe_cast_one_to_many_metadata(metadatas))\n\u001b[1;32m    184\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m metadatas \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    185\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    186\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/rag/venv/lib/python3.12/site-packages/chromadb/api/types.py:273\u001b[0m, in \u001b[0;36mvalidate_ids\u001b[0;34m(ids)\u001b[0m\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected IDs to be a list, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(ids)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m as IDs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(ids) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 273\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected IDs to be a non-empty list, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(ids)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m IDs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    274\u001b[0m seen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[1;32m    275\u001b[0m dups \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[0;31mValueError\u001b[0m: Expected IDs to be a non-empty list, got 0 IDs"
     ]
    }
   ],
   "source": [
    "# Vector store ve retriever'i yükle\n",
    "vector_store = get_vectorstore(question, initials.model, initials.data_directory, initials.embedding)\n",
    "retriever = vector_store.as_retriever()\n",
    "\n",
    "# Geri getirme işlevi için yapılandırılmış LLM\n",
    "structured_llm_grader = initials.model.with_structured_output(GradeDocuments)\n",
    "# Halüsinasyon işlevi için yapılandırılmış LLM\n",
    "structured_llm_hallucination_grader = initials.model.with_structured_output(GradeHallucinations)\n",
    "# Cevap işlevi için yapılandırılmış LLM\n",
    "structured_llm_answer_grader = initials.model.with_structured_output(GradeAnswer)\n",
    "\n",
    "# Soru yönlendirme işlevi için yapılandırılmış LLM\n",
    "structured_llm_router = initials.model.with_structured_output(routing.RouteUserQuery)\n",
    "\n",
    "# Promt'ları bağlama\n",
    "retrieval_grader = initials.grade_prompt | structured_llm_grader\n",
    "hallucination_grader = initials.hallucination_prompt | structured_llm_hallucination_grader\n",
    "answer_grader = initials.answer_prompt | structured_llm_answer_grader\n",
    "question_rewriter = prompts.re_write_prompt | initials.model | StrOutputParser()\n",
    "\n",
    "# Retrieving relevant documents\n",
    "grader_docs = retriever.get_relevant_documents(question)\n",
    "if not grader_docs:\n",
    "    raise ValueError(\"No relevant documents found for the question.\")\n",
    "\n",
    "# Retrieved document contents\n",
    "doc_txt = \" \".join([doc.page_content for doc in grader_docs])\n",
    "\n",
    "# Chroma vector store fonksiyonu\n",
    "def get_vectorstore(question, model, data_directory, embedding):\n",
    "    # Özetleri yükleme\n",
    "    summaries = load_summaries(get_specific_directory(question, model, data_directory))\n",
    "    \n",
    "    # Özetsiz durumda hata verme\n",
    "    if not summaries:\n",
    "        raise ValueError(\"No summaries found for the given question.\")\n",
    "    \n",
    "    print(f\"Loaded summaries: {len(summaries)}\")\n",
    "    \n",
    "    # Chroma vector store oluşturma\n",
    "    summary_vectorstore = create_chroma_vectorstore(summaries, embedding)\n",
    "    return summary_vectorstore\n",
    "\n",
    "# Chroma vector store'u oluşturma fonksiyonu\n",
    "def create_chroma_vectorstore(summaries, embedding):\n",
    "    # Dokümanları oluşturma\n",
    "    documents = [Document(page_content=summary) for summary in summaries]\n",
    "    \n",
    "    # Geçerli ID ve içerik kontrolü\n",
    "    if not documents or any(doc.page_content is None for doc in documents):\n",
    "        raise ValueError(\"Documents must have valid content and IDs.\")\n",
    "    \n",
    "    # Document ID'lerini ayarlama\n",
    "    ids = [f\"id_{i}\" for i in range(len(documents))] if documents else None\n",
    "    \n",
    "    # ID ve dokümanların doğruluğunu kontrol etme\n",
    "    if not ids or len(ids) == 0:\n",
    "        raise ValueError(\"Expected IDs to be a non-empty list.\")\n",
    "    \n",
    "    print(f\"Documents created: {len(documents)}\")\n",
    "    print(f\"Document IDs: {ids}\")\n",
    "    \n",
    "    # Chroma vektör mağazasını oluşturma\n",
    "    summary_vectorstore = Chroma.from_documents(documents=documents, embedding=embedding, ids=ids)\n",
    "    return summary_vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings calculated: 0\n",
      "Total documents created: 0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected IDs to be a non-empty list, got 0 IDs",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n",
      "\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Vector store ve retriever'i yükle\u001b[39;00m\n",
      "\u001b[0;32m----> 2\u001b[0m vector_store \u001b[38;5;241m=\u001b[39m \u001b[43mget_vectorstore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitials\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitials\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_directory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitials\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m      3\u001b[0m retriever \u001b[38;5;241m=\u001b[39m vector_store\u001b[38;5;241m.\u001b[39mas_retriever()\n",
      "\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Geri getirme işlevi için yapılandırılmış LLM\u001b[39;00m\n",
      "\n",
      "File \u001b[0;32m~/Desktop/rag/indexing.py:154\u001b[0m, in \u001b[0;36mget_vectorstore\u001b[0;34m(question, model, data_directory, embedding)\u001b[0m\n",
      "\u001b[1;32m    152\u001b[0m summaries \u001b[38;5;241m=\u001b[39m load_summaries(get_specific_directory(question, model, data_directory))\n",
      "\u001b[1;32m    153\u001b[0m \u001b[38;5;66;03m# Chroma vektör mağazasını oluşturun\u001b[39;00m\n",
      "\u001b[0;32m--> 154\u001b[0m summary_vectorstore \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_chroma_vectorstore\u001b[49m\u001b[43m(\u001b[49m\u001b[43msummaries\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    155\u001b[0m \u001b[38;5;66;03m# Chroma'dan bir retriever oluşturun\u001b[39;00m\n",
      "\u001b[1;32m    156\u001b[0m summary_retriever \u001b[38;5;241m=\u001b[39m summary_vectorstore\u001b[38;5;241m.\u001b[39mas_retriever(search_kwargs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mk\u001b[39m\u001b[38;5;124m\"\u001b[39m: TOP_N})    \n",
      "\n",
      "File \u001b[0;32m~/Desktop/rag/indexing.py:82\u001b[0m, in \u001b[0;36mcreate_chroma_vectorstore\u001b[0;34m(summaries, embedding)\u001b[0m\n",
      "\u001b[1;32m     79\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal documents created: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(documents)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# Create Chroma vectorstore from documents\u001b[39;00m\n",
      "\u001b[0;32m---> 82\u001b[0m summary_vectorstore \u001b[38;5;241m=\u001b[39m \u001b[43mChroma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m summary_vectorstore\n",
      "\n",
      "File \u001b[0;32m~/Desktop/rag/venv/lib/python3.12/site-packages/langchain_chroma/vectorstores.py:1128\u001b[0m, in \u001b[0;36mChroma.from_documents\u001b[0;34m(cls, documents, embedding, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[0m\n",
      "\u001b[1;32m   1126\u001b[0m texts \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n",
      "\u001b[1;32m   1127\u001b[0m metadatas \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n",
      "\u001b[0;32m-> 1128\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_texts\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[1;32m   1129\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtexts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1130\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1131\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1132\u001b[0m \u001b[43m    \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1133\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1134\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpersist_directory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpersist_directory\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_settings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient_settings\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1136\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1137\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection_metadata\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1138\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1139\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[0;32m~/Desktop/rag/venv/lib/python3.12/site-packages/langchain_chroma/vectorstores.py:1089\u001b[0m, in \u001b[0;36mChroma.from_texts\u001b[0;34m(cls, texts, embedding, metadatas, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[0m\n",
      "\u001b[1;32m   1083\u001b[0m         chroma_collection\u001b[38;5;241m.\u001b[39madd_texts(\n",
      "\u001b[1;32m   1084\u001b[0m             texts\u001b[38;5;241m=\u001b[39mbatch[\u001b[38;5;241m3\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m batch[\u001b[38;5;241m3\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m [],\n",
      "\u001b[1;32m   1085\u001b[0m             metadatas\u001b[38;5;241m=\u001b[39mbatch[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m batch[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n",
      "\u001b[1;32m   1086\u001b[0m             ids\u001b[38;5;241m=\u001b[39mbatch[\u001b[38;5;241m0\u001b[39m],\n",
      "\u001b[1;32m   1087\u001b[0m         )\n",
      "\u001b[1;32m   1088\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;32m-> 1089\u001b[0m     \u001b[43mchroma_collection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mids\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m   1090\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m chroma_collection\n",
      "\n",
      "File \u001b[0;32m~/Desktop/rag/venv/lib/python3.12/site-packages/langchain_chroma/vectorstores.py:557\u001b[0m, in \u001b[0;36mChroma.add_texts\u001b[0;34m(self, texts, metadatas, ids, **kwargs)\u001b[0m\n",
      "\u001b[1;32m    551\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_collection\u001b[38;5;241m.\u001b[39mupsert(\n",
      "\u001b[1;32m    552\u001b[0m             embeddings\u001b[38;5;241m=\u001b[39membeddings_without_metadatas,  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n",
      "\u001b[1;32m    553\u001b[0m             documents\u001b[38;5;241m=\u001b[39mtexts_without_metadatas,\n",
      "\u001b[1;32m    554\u001b[0m             ids\u001b[38;5;241m=\u001b[39mids_without_metadatas,\n",
      "\u001b[1;32m    555\u001b[0m         )\n",
      "\u001b[1;32m    556\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;32m--> 557\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_collection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupsert\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[1;32m    558\u001b[0m \u001b[43m        \u001b[49m\u001b[43membeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n",
      "\u001b[1;32m    559\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    560\u001b[0m \u001b[43m        \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    561\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    562\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ids\n",
      "\n",
      "File \u001b[0;32m~/Desktop/rag/venv/lib/python3.12/site-packages/chromadb/api/models/Collection.py:298\u001b[0m, in \u001b[0;36mCollection.upsert\u001b[0;34m(self, ids, embeddings, metadatas, documents, images, uris)\u001b[0m\n",
      "\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupsert\u001b[39m(\n",
      "\u001b[1;32m    268\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n",
      "\u001b[1;32m    269\u001b[0m     ids: OneOrMany[ID],\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m    279\u001b[0m     uris: Optional[OneOrMany[URI]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "\u001b[1;32m    280\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m    281\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Update the embeddings, metadatas or documents for provided ids, or create them if they don't exist.\u001b[39;00m\n",
      "\u001b[1;32m    282\u001b[0m \n",
      "\u001b[1;32m    283\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m    290\u001b[0m \u001b[38;5;124;03m        None\u001b[39;00m\n",
      "\u001b[1;32m    291\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[1;32m    292\u001b[0m     (\n",
      "\u001b[1;32m    293\u001b[0m         ids,\n",
      "\u001b[1;32m    294\u001b[0m         embeddings,\n",
      "\u001b[1;32m    295\u001b[0m         metadatas,\n",
      "\u001b[1;32m    296\u001b[0m         documents,\n",
      "\u001b[1;32m    297\u001b[0m         uris,\n",
      "\u001b[0;32m--> 298\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_and_prepare_upsert_request\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[1;32m    299\u001b[0m \u001b[43m        \u001b[49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muris\u001b[49m\n",
      "\u001b[1;32m    300\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    302\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39m_upsert(\n",
      "\u001b[1;32m    303\u001b[0m         collection_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid,\n",
      "\u001b[1;32m    304\u001b[0m         ids\u001b[38;5;241m=\u001b[39mids,\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m    308\u001b[0m         uris\u001b[38;5;241m=\u001b[39muris,\n",
      "\u001b[1;32m    309\u001b[0m     )\n",
      "\n",
      "File \u001b[0;32m~/Desktop/rag/venv/lib/python3.12/site-packages/chromadb/api/models/CollectionCommon.py:540\u001b[0m, in \u001b[0;36mCollectionCommon._validate_and_prepare_upsert_request\u001b[0;34m(self, ids, embeddings, metadatas, documents, images, uris)\u001b[0m\n",
      "\u001b[1;32m    513\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_and_prepare_upsert_request\u001b[39m(\n",
      "\u001b[1;32m    514\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n",
      "\u001b[1;32m    515\u001b[0m     ids: OneOrMany[ID],\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m    531\u001b[0m     Optional[URIs],\n",
      "\u001b[1;32m    532\u001b[0m ]:\n",
      "\u001b[1;32m    533\u001b[0m     (\n",
      "\u001b[1;32m    534\u001b[0m         ids,\n",
      "\u001b[1;32m    535\u001b[0m         embeddings,\n",
      "\u001b[1;32m    536\u001b[0m         metadatas,\n",
      "\u001b[1;32m    537\u001b[0m         documents,\n",
      "\u001b[1;32m    538\u001b[0m         images,\n",
      "\u001b[1;32m    539\u001b[0m         uris,\n",
      "\u001b[0;32m--> 540\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_embedding_set\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[1;32m    541\u001b[0m \u001b[43m        \u001b[49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muris\u001b[49m\n",
      "\u001b[1;32m    542\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    544\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m embeddings \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m    545\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m documents \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\n",
      "File \u001b[0;32m~/Desktop/rag/venv/lib/python3.12/site-packages/chromadb/api/models/CollectionCommon.py:174\u001b[0m, in \u001b[0;36mCollectionCommon._validate_embedding_set\u001b[0;34m(self, ids, embeddings, metadatas, documents, images, uris, require_embeddings_or_data)\u001b[0m\n",
      "\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_embedding_set\u001b[39m(\n",
      "\u001b[1;32m    153\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n",
      "\u001b[1;32m    154\u001b[0m     ids: OneOrMany[ID],\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m    172\u001b[0m     Optional[URIs],\n",
      "\u001b[1;32m    173\u001b[0m ]:\n",
      "\u001b[0;32m--> 174\u001b[0m     valid_ids \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_ids\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_cast_one_to_many_ids\u001b[49m\u001b[43m(\u001b[49m\u001b[43mids\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    175\u001b[0m     valid_embeddings \u001b[38;5;241m=\u001b[39m (\n",
      "\u001b[1;32m    176\u001b[0m         validate_embeddings(\n",
      "\u001b[1;32m    177\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_normalize_embeddings(maybe_cast_one_to_many_embedding(embeddings))\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m    180\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;32m    181\u001b[0m     )\n",
      "\u001b[1;32m    182\u001b[0m     valid_metadatas \u001b[38;5;241m=\u001b[39m (\n",
      "\u001b[1;32m    183\u001b[0m         validate_metadatas(maybe_cast_one_to_many_metadata(metadatas))\n",
      "\u001b[1;32m    184\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m metadatas \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;32m    185\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;32m    186\u001b[0m     )\n",
      "\n",
      "File \u001b[0;32m~/Desktop/rag/venv/lib/python3.12/site-packages/chromadb/api/types.py:273\u001b[0m, in \u001b[0;36mvalidate_ids\u001b[0;34m(ids)\u001b[0m\n",
      "\u001b[1;32m    271\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected IDs to be a list, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(ids)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m as IDs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(ids) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;32m--> 273\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected IDs to be a non-empty list, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(ids)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m IDs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;32m    274\u001b[0m seen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[1;32m    275\u001b[0m dups \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "\n",
      "\u001b[0;31mValueError\u001b[0m: Expected IDs to be a non-empty list, got 0 IDs"
     ]
    }
   ],
   "source": [
    "# Vector store ve retriever'i yükle\n",
    "vector_store = get_vectorstore(question, initials.model, initials.data_directory, initials.embedding)\n",
    "retriever = vector_store.as_retriever()\n",
    "\n",
    "# Geri getirme işlevi için yapılandırılmış LLM\n",
    "structured_llm_grader = initials.model.with_structured_output(GradeDocuments)\n",
    "# Halüsinasyon işlevi için yapılandırılmış LLM\n",
    "structured_llm_hallucination_grader = initials.model.with_structured_output(GradeHallucinations)\n",
    "# Cevap işlevi için yapılandırılmış LLM\n",
    "structured_llm_answer_grader = initials.model.with_structured_output(GradeAnswer)\n",
    "\n",
    "# Soru yönlendirme işlevi için yapılandırılmış LLM\n",
    "structured_llm_router = initials.model.with_structured_output(routing.RouteUserQuery)\n",
    "\n",
    "# Promt'ları bağlama\n",
    "retrieval_grader = initials.grade_prompt | structured_llm_grader\n",
    "hallucination_grader = initials.hallucination_prompt | structured_llm_hallucination_grader\n",
    "answer_grader = initials.answer_prompt | structured_llm_answer_grader\n",
    "question_rewriter = prompts.re_write_prompt | initials.model | StrOutputParser()\n",
    "\n",
    "# Retrieving relevant documents\n",
    "grader_docs = retriever.get_relevant_documents(question)\n",
    "if not grader_docs:\n",
    "    raise ValueError(\"No relevant documents found for the question.\")\n",
    "\n",
    "# Retrieved document contents\n",
    "doc_txt = \" \".join([doc.page_content for doc in grader_docs])\n",
    "\n",
    "# Chroma vector store fonksiyonu\n",
    "def get_vectorstore(question, model, data_directory, embedding):\n",
    "    # Özetleri yükleme\n",
    "    summaries = load_summaries(get_specific_directory(question, model, data_directory))\n",
    "    \n",
    "    # Özetsiz durumda hata verme\n",
    "    if not summaries:\n",
    "        raise ValueError(\"No summaries found for the given question.\")\n",
    "    \n",
    "    print(f\"Loaded summaries: {len(summaries)}\")\n",
    "    \n",
    "    # Chroma vector store oluşturma\n",
    "    summary_vectorstore = create_chroma_vectorstore(summaries, embedding)\n",
    "    return summary_vectorstore\n",
    "\n",
    "# Chroma vector store'u oluşturma fonksiyonu\n",
    "def create_chroma_vectorstore(summaries, embedding):\n",
    "    # Dokümanları oluşturma\n",
    "    documents = [Document(page_content=summary) for summary in summaries]\n",
    "    \n",
    "    # Geçerli ID ve içerik kontrolü\n",
    "    if not documents or any(doc.page_content is None for doc in documents):\n",
    "        raise ValueError(\"Documents must have valid content and IDs.\")\n",
    "    \n",
    "    # Document ID'lerini ayarlama\n",
    "    ids = [f\"id_{i}\" for i in range(len(documents))] if documents else None\n",
    "    \n",
    "    # ID ve dokümanların doğruluğunu kontrol etme\n",
    "    if not ids or len(ids) == 0:\n",
    "        raise ValueError(\"Expected IDs to be a non-empty list.\")\n",
    "    \n",
    "    print(f\"Documents created: {len(documents)}\")\n",
    "    print(f\"Document IDs: {ids}\")\n",
    "    \n",
    "    # Chroma vektör mağazasını oluşturma\n",
    "    summary_vectorstore = Chroma.from_documents(documents=documents, embedding=embedding, ids=ids)\n",
    "    return summary_vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === GRAPH ===\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents the state of our graph.\n",
    "\n",
    "    Attributes:\n",
    "        question: question\n",
    "        generation: LLM generation\n",
    "        web_search: whether to add search\n",
    "        documents: list of documents\n",
    "    \"\"\"\n",
    "    question: str\n",
    "    generation: str\n",
    "    web_search: str\n",
    "    documents: List[str]\n",
    "\n",
    "### Nodes\n",
    "\n",
    "\n",
    "## BURADA ARGÜMAN OLARAK RETRIEVER YOK NORMALDE CALISMIYORSA CIKAR\n",
    "def retrieve(state, retriever):\n",
    "    \"\"\"\n",
    "    Retrieve documents\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, documents, that contains retrieved documents\n",
    "    \"\"\"\n",
    "    print(\"---RETRIEVE---\")\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    # Retrieval\n",
    "    documents = retriever.get_relevant_documents(question)\n",
    "    print(\"\\nROUTED DOCS: \",documents)\n",
    "    return {\"documents\": documents, \"question\": question}\n",
    "\n",
    "def generate(state):\n",
    "    \"\"\"\n",
    "    Generate answer\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, generation, that contains LLM generation\n",
    "    \"\"\"\n",
    "    print(\"---GENERATE---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    rag_chain = prompts.prompt_telekom | initials.model | StrOutputParser()\n",
    "    #print(documents)\n",
    "\n",
    "    # RAG generation\n",
    "    generation = rag_chain.invoke({\"context\": documents, \"question\": question})\n",
    "    print(\"\\nDOCUMENTS:\", documents)   \n",
    "    print(\"\\nAnswer:\", generation)\n",
    "\n",
    "    return {\"documents\": documents, \"question\": question, \"generation\": generation}\n",
    "\n",
    "\n",
    "def grade_documents(state):\n",
    "    \"\"\"\n",
    "    Determines whether the retrieved documents are relevant to the question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Updates documents key with only filtered relevant documents\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---CHECK DOCUMENT RELEVANCE TO QUESTION---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # Score each doc\n",
    "    filtered_docs = []\n",
    "    web_search = \"No\" # DIKKAT! SELF-RAG'ta burayi cikarmis\n",
    "    for d in documents:\n",
    "        score = retrieval_grader.invoke({\"question\": question, \"document\": d.page_content})\n",
    "        print(\"\\nORJINAL SORU:\", question)\n",
    "        print(d.page_content)\n",
    "        \n",
    "        grade = score.binary_score\n",
    "        if grade == \"yes\":\n",
    "            print(\"---GRADE: DOCUMENT RELEVANT---\")\n",
    "            filtered_docs.append(d)\n",
    "        else:\n",
    "            print(\"---GRADE: DOCUMENT NOT RELEVANT---\")\n",
    "            web_search = \"Yes\"\n",
    "            continue\n",
    "    print(\"\\nRELEVANT CONTEXT: \", filtered_docs)\n",
    "    return {\"documents\": filtered_docs, \"question\": question, \"web_search\": web_search}\n",
    "\n",
    "\n",
    "def transform_query(state):\n",
    "    \"\"\"\n",
    "    Transform the query to produce a better question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Updates question key with a re-phrased question\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---TRANSFORM QUERY---\")\n",
    "    question = state[\"question\"]\n",
    "    #documents = state[\"documents\"]\n",
    "\n",
    "    # Re-write question\n",
    "    better_question = question_rewriter.invoke({\"question\": question})\n",
    "    #return {\"documents\": documents, \"question\": better_question}\n",
    "    return {\"question\": better_question}\n",
    "\n",
    "def web_search(state):\n",
    "    \"\"\"\n",
    "    Web search based on the re-phrased question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Updates documents key with appended web results\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---WEB SEARCH---\")\n",
    "\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    #filtered_docs = state[\"filtered_docs\"]\n",
    "    print(question)\n",
    "    # Web search\n",
    "    web_search_tool = tavily_client.qna_search(question)\n",
    "    web_results = Document(page_content=web_search_tool)\n",
    "\n",
    "    #orjinalinde direkt burdaki gibi retriever'dan aliyor ama ben filtered_docs alicam sadece\n",
    "    #documents = retriever.get_relevant_documents(question)\n",
    "    #documents.append(filtered_docs)\n",
    "    documents.append(web_results)\n",
    "    #print(documents)\n",
    "    return {\"documents\": documents, \"question\": question}\n",
    "\n",
    "### Edges\n",
    "\n",
    "def route_question(state):\n",
    "    \"\"\"\n",
    "    Route question to web search or RAG \n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        str: Next node to call\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---ROUTE QUESTION---\")\n",
    "    source = structured_llm_router.invoke([SystemMessage(content=routing.query_router_instructions)] + [HumanMessage(content=state[\"question\"])]) \n",
    "    if source.datasource == 'websearch':\n",
    "        print(\"---ROUTE QUESTION TO WEB SEARCH---\")\n",
    "        return \"websearch\"\n",
    "    elif source.datasource == 'vectorstore':\n",
    "        print(\"---ROUTE QUESTION TO RAG---\")\n",
    "        return \"vectorstore\"\n",
    "\n",
    "\n",
    "def decide_to_generate(state):\n",
    "    \"\"\"\n",
    "    Determines whether to generate an answer, or re-generate a question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        str: Binary decision for next node to call\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---ASSESS GRADED DOCUMENTS---\")\n",
    "    state[\"question\"]\n",
    "    web_search = state[\"web_search\"]\n",
    "    print(web_search)\n",
    "    state[\"documents\"]\n",
    "    #state[\"filtered_docs\"]\n",
    "\n",
    "    if web_search == \"Yes\":\n",
    "        # All documents have been filtered check_relevance\n",
    "        # We will re-generate a new query\n",
    "        print(\n",
    "            \"---DECISION: SOME DOCUMENTS ARE NOT RELEVANT TO QUESTION, WEB SEARCH---\"\n",
    "        )\n",
    "        return \"web_search_node\"\n",
    "    else:\n",
    "        # We have relevant documents, so generate answer\n",
    "        print(\"---DECISION: GENERATE---\")\n",
    "        return \"generate\"\n",
    "\n",
    "\n",
    "def grade_generation_v_documents_and_question(state):\n",
    "    \"\"\"\n",
    "    Determines whether the generation is grounded in the document and answers question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        str: Decision for next node to call\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---CHECK HALLUCINATIONS---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    generation = state[\"generation\"]\n",
    "    print(\"\\nQUESTION:\", question)\n",
    "    print(\"\\nDOCUMENTS:\", documents)\n",
    "    print(\"\\nGENERATION:\", generation)\n",
    "\n",
    "    score = hallucination_grader.invoke(\n",
    "        {\"documents\": documents, \"generation\": generation}\n",
    "    )\n",
    "    grade = score.binary_score\n",
    "    print(grade)\n",
    "\n",
    "    # Check hallucination\n",
    "    if grade == \"yes\":\n",
    "        print(\"---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\")\n",
    "        # Check question-answering\n",
    "        print(\"---GRADE GENERATION vs QUESTION---\")\n",
    "        score = answer_grader.invoke({\"question\": question, \"generation\": generation})\n",
    "        grade = score.binary_score\n",
    "        if grade == \"yes\":\n",
    "            print(\"---DECISION: GENERATION ADDRESSES QUESTION---\")\n",
    "            return \"useful\"\n",
    "        else:\n",
    "            print(\"---DECISION: GENERATION DOES NOT ADDRESS QUESTION---\")\n",
    "            return \"not useful\"\n",
    "    else:\n",
    "        pprint(\"---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---\")\n",
    "        return \"not supported\"\n",
    "\n",
    "\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# Define the nodes\n",
    "workflow.add_node(\"retrieve\", retrieve)  # retrieve\n",
    "workflow.add_node(\"grade_documents\", grade_documents)  # grade documents\n",
    "workflow.add_node(\"generate\", generate)  # generatae\n",
    "workflow.add_node(\"transform_query\", transform_query)  # transform_query\n",
    "workflow.add_node(\"web_search_node\", web_search)  # web search\n",
    "\n",
    "# Build graph\n",
    "# workflow.set_entry_point(\"transform_query\") bu sekilde de grafik'e baslanabilir, alttakiyle ayni.\n",
    "workflow.add_edge(START, \"transform_query\")\n",
    "workflow.add_edge(\"transform_query\", \"retrieve\")\n",
    "workflow.add_edge(\"retrieve\", \"grade_documents\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"grade_documents\",\n",
    "    decide_to_generate,\n",
    "    {\n",
    "        \"web_search_node\": \"web_search_node\",\n",
    "        \"generate\": \"generate\",\n",
    "    },\n",
    ")\n",
    "workflow.add_edge(\"web_search_node\", \"generate\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"generate\",\n",
    "    grade_generation_v_documents_and_question,\n",
    "    {\n",
    "        \"not supported\": \"generate\",\n",
    "        \"useful\": END,\n",
    "        \"not useful\": \"transform_query\",\n",
    "    },\n",
    ")\n",
    "\n",
    "# Compile\n",
    "app = workflow.compile()\n",
    "\n",
    "# Run\n",
    "inputs = {\"question\": question}\n",
    "for output in app.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        # Node\n",
    "        pprint(f\"Node '{key}':\")\n",
    "        # Optional: print full state at each node\n",
    "        # pprint.pprint(value[\"keys\"], indent=2, width=80, depth=None)\n",
    "    pprint(\"\\n---\\n\")\n",
    "\n",
    "# Final generation\n",
    "response = value[\"generation\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
